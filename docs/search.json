[{"path":"/articles/Introduction.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Introduction to EDA functions","text":"tukeyedar package houses functions used Exploratory Data Analysis (EDA). functions inspired work published John Tukey, David Hoaglin Frederick Mosteller (see references bottom document). Many plots generated functions necessarily geared publication public dissemination designed focus viewer’s attention patterns generated plots (hence reason light colored axes missing axis labels plots ). functions available package listed : access functions, ensure tukeyedar properly loaded: brief description examples function presented next.","code":"library(tukeyedar)"},{"path":"/articles/Introduction.html","id":"eda_boxls","dir":"Articles","previous_headings":"","what":"eda_boxls","title":"Introduction to EDA functions","text":"Usage: boxls generate boxplots variable x conditioned variable fac. data must long form data frame, dat.  boxplots can plotted horizontally setting horiz parameter TRUE.  equalize level median values set type l.  equalize level spread, set type ls.  Note l ls options, boxplots ordered based non-equalized level values.","code":"eda_boxls(dat, x,fac,outlier=TRUE, out.txt, type=\"l\", horiz=FALSE) eda_boxls(mtcars, mpg, cyl, type=\"none\", out.txt=mpg ) eda_boxls(mtcars, mpg, cyl, type=\"none\", out.txt = mpg, horiz=TRUE) eda_boxls(mtcars,mpg, cyl, type=\"l\", out.txt = mpg) eda_boxls(mtcars, mpg, cyl, type=\"ls\", out.txt = mpg)"},{"path":"/articles/Introduction.html","id":"trim-family","dir":"Articles","previous_headings":"","what":"Trim family","title":"Introduction to EDA functions","text":"family trimming functions trim vector dataframe sorted vector column values. Note NA values need removed input vector column elements running trim functions.","code":""},{"path":"/articles/Introduction.html","id":"eda_trim","dir":"Articles","previous_headings":"Trim family","what":"eda_trim","title":"Introduction to EDA functions","text":"Usage: eda_trim trim lower upper values vector based fraction vector length (defined parameter prop) based number values (defined parameter num). example, want remove 10% smallest 10% largest values vector x, type following:","code":"eda_trim(x, prop=.05, num = 0) x <- 1:10 eda_trim(x, prop = 0.1) #>  [1] 2 3 4 5 6 7 8 9"},{"path":"/articles/Introduction.html","id":"eda_ltrim","dir":"Articles","previous_headings":"Trim family","what":"eda_ltrim","title":"Introduction to EDA functions","text":"Usage: eda_ltrim trim lower values vector based fraction (defined parameter prop) number points (defined parameter num). example, want remove 5% smallest values vector x, type following: remove number values, use num option. example, remove 3 smallest values, type:","code":"eda_ltrim(x, prop=.05, num = 0) x <- 1:20 eda_ltrim(x, prop = 0.05) #>   [1]  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 eda_ltrim(x, num = 3) #>   [1]  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20"},{"path":"/articles/Introduction.html","id":"eda_rtrim","dir":"Articles","previous_headings":"Trim family","what":"eda_rtrim","title":"Introduction to EDA functions","text":"Usage: eda_rtrim works way ltrim except largest values trimmed vector. example, remove largest 10% values x, type: remove number largest values, use num option. example, remove 2 largest values, type:","code":"eda_rtrim(x, prop=.05, num = 0) x <- 1:10 eda_rtrim(x, prop = 0.1) #>  [1] 1 2 3 4 5 6 7 8 9 eda_rtrim(x, num = 2) #>  [1] 1 2 3 4 5 6 7 8"},{"path":"/articles/Introduction.html","id":"eda_trim_df","dir":"Articles","previous_headings":"Trim family","what":"eda_trim_df","title":"Introduction to EDA functions","text":"Usage: eda_trim_df trim records dataframe based one column’s smallest largest values. column’s lower upper trimmed values based fraction (defined parameter prop) number records (defined parameter num). example, want remove records dataframe trees based 10% smallest 10% largest Height values, type: Note output dataframe sorted x column.","code":"eda_trim_df(dat, x, prop=.05, num = 0) eda_trim_df(trees, Height, prop = 0.10) #>     Girth Height Volume #>  7   11.0     66   15.6 #>  14  11.7     69   21.3 #>  1    8.3     70   10.3 #>  19  13.7     71   25.7 #>  4   10.5     72   16.4 #>  24  16.0     72   38.3 #>  16  12.9     74   22.2 #>  23  14.5     74   36.3 #>  8   11.0     75   18.2 #>  10  11.2     75   19.9 #>  15  12.0     75   19.1 #>  12  11.4     76   21.0 #>  13  11.4     76   21.4 #>  25  16.3     77   42.6 #>  21  14.0     78   34.5 #>  11  11.3     79   24.2 #>  9   11.1     80   22.6 #>  22  14.2     80   31.7 #>  28  17.9     80   58.3 #>  29  18.0     80   51.5 #>  30  18.0     80   51.0 #>  5   10.7     81   18.8 #>  26  17.3     81   55.4 #>  27  17.5     82   55.7 #>  6   10.8     83   19.7"},{"path":"/articles/Introduction.html","id":"eda_ltrim_df","dir":"Articles","previous_headings":"Trim family","what":"eda_ltrim_df","title":"Introduction to EDA functions","text":"Usage: eda_ltrim_df trim records dataframe associated one column’s smallest values. smallest values identified based fraction (defined parameter prop) number records (defined parameter num). example, want remove records dataframe trees based 25% smallest Height values, type following: records associated 15 smallest Volume values removed, invoke num option:","code":"eda_ltrim_df(dat, x, prop=.05, num = 0) eda_ltrim_df(trees, Height, prop = 0.25) #>     Girth Height Volume #>  16  12.9     74   22.2 #>  23  14.5     74   36.3 #>  8   11.0     75   18.2 #>  10  11.2     75   19.9 #>  15  12.0     75   19.1 #>  12  11.4     76   21.0 #>  13  11.4     76   21.4 #>  25  16.3     77   42.6 #>  21  14.0     78   34.5 #>  11  11.3     79   24.2 #>  9   11.1     80   22.6 #>  22  14.2     80   31.7 #>  28  17.9     80   58.3 #>  29  18.0     80   51.5 #>  30  18.0     80   51.0 #>  5   10.7     81   18.8 #>  26  17.3     81   55.4 #>  27  17.5     82   55.7 #>  6   10.8     83   19.7 #>  17  12.9     85   33.8 #>  18  13.3     86   27.4 #>  31  20.6     87   77.0 eda_ltrim_df(trees, Volume, num = 15) #>     Girth Height Volume #>  11  11.3     79   24.2 #>  20  13.8     64   24.9 #>  19  13.7     71   25.7 #>  18  13.3     86   27.4 #>  22  14.2     80   31.7 #>  17  12.9     85   33.8 #>  21  14.0     78   34.5 #>  23  14.5     74   36.3 #>  24  16.0     72   38.3 #>  25  16.3     77   42.6 #>  30  18.0     80   51.0 #>  29  18.0     80   51.5 #>  26  17.3     81   55.4 #>  27  17.5     82   55.7 #>  28  17.9     80   58.3 #>  31  20.6     87   77.0"},{"path":"/articles/Introduction.html","id":"eda_rtrim_df","dir":"Articles","previous_headings":"Trim family","what":"eda_rtrim_df","title":"Introduction to EDA functions","text":"Usage: eda_rtrim_df trim records dataframe associated one column’s largest values. largest values identified based fraction (defined parameter prop) number records (defined parameter num). example, want remove records dataframe trees associated 45% largest Volume values, type following: records associated 20 largest Girth values removed, invoke num option:","code":"eda_rtrim_df(dat,prop=.05, x, num = 0) eda_rtrim_df(trees, Volume, prop = 0.45) #>     Girth Height Volume #>  3    8.8     63   10.2 #>  1    8.3     70   10.3 #>  2    8.6     65   10.3 #>  7   11.0     66   15.6 #>  4   10.5     72   16.4 #>  8   11.0     75   18.2 #>  5   10.7     81   18.8 #>  15  12.0     75   19.1 #>  6   10.8     83   19.7 #>  10  11.2     75   19.9 #>  12  11.4     76   21.0 #>  14  11.7     69   21.3 #>  13  11.4     76   21.4 #>  16  12.9     74   22.2 #>  9   11.1     80   22.6 #>  11  11.3     79   24.2 #>  20  13.8     64   24.9 eda_rtrim_df(trees, Girth, num = 20) #>     Girth Height Volume #>  1    8.3     70   10.3 #>  2    8.6     65   10.3 #>  3    8.8     63   10.2 #>  4   10.5     72   16.4 #>  5   10.7     81   18.8 #>  6   10.8     83   19.7 #>  7   11.0     66   15.6 #>  8   11.0     75   18.2 #>  9   11.1     80   22.6 #>  10  11.2     75   19.9 #>  11  11.3     79   24.2"},{"path":"/articles/Introduction.html","id":"eda_re","dir":"Articles","previous_headings":"","what":"eda_re","title":"Introduction to EDA functions","text":"Usage: eda_re used re-express data using one two transformation techniques: Box-Cox transformation Tukey’s power transformation. $$ \\[\\begin{equation} T_{Tukey} = \\begin{cases} x^p , & p \\neq 0 \\\\               log(x), & p = 0 \\\\                \\end{cases} \\end{equation}\\] $$ \\[ \\begin{equation} T_{Box-Cox} = \\begin{cases} \\frac{x^p - 1}{p}, & p \\neq  0 \\\\               log(x), & p = 0 \\end{cases} \\end{equation} \\] transformation techniques generate similar distributions power p 0 greater, differ distributions power negative. example, re-expressing mtcars$mpg using inverse power (p = -1), Tukey’s re-expression change data order Box-Cox transformation shown following plots:  original data shows negative relationship mpg disp; Tukey re-expression takes inverse mpg changes nature relationship y x variable whe positive relationship re-expressed mpg variable disp (note simply changing sign re-expressed value, -x^(-1) maintains nature original relationship); Box-Cox transformation, hand, maintains negative relationship. choice re-expression depend analysis context. example, want easily interpretable transformation, opt Tukey re-expression. want compare shape transformed variables, Box-Cox approach better suited.","code":"eda_re(x, p = 0, tukey = FALSE) plot(mpg ~ disp, mtcars, main=\"Original data\") plot(eda_re(mpg, -1, tukey=TRUE) ~ disp, mtcars, main=\"Tukey\") plot(eda_re(mpg, -1, tukey=FALSE) ~ disp, mtcars, main=\"Box-Cox\")"},{"path":"/articles/Introduction.html","id":"eda_lsum","dir":"Articles","previous_headings":"","what":"eda_lsum","title":"Introduction to EDA functions","text":"Usage: letter value summary introduced John Tukey extends boxplot’s 5 number summary exploring symmetry batch depth levels half (median) fourth (quartiles). can helfpul fine-tuning re-expression parameters. example, applying letter value summary hp variable shows consistent skew across letter levels.  can make use letter summaries fine-tune re-expression power symmetrizes data:  goal find re-expression minimizes systematic skew across letter summary values. power -0.25 seems nice job symmetrizing distribution. detailed explanation letter summaries calculation click .","code":"eda_lsum((x, l = 5, all = TRUE)) lsum <- eda_lsum(mtcars$hp,l=5) lsum #>    letter depth lower    mid upper spread #>  1      M  16.5 123.0 123.00 123.0    0.0 #>  2      H   8.5  96.0 138.00 180.0   84.0 #>  3      E   4.5  66.0 151.75 237.5  171.5 #>  4      D   2.5  63.5 159.00 254.5  191.0 #>  5      C   1.5  57.0 178.25 299.5  242.5 with(lsum, dotchart(x=mid, labels=letter,pch=20, pt.cex=1.5) ) p <- c(-1/2, -1/4, 0, 1/4, 1/2) OP <- par(mfrow=c(1,5)) for (i in p) {   lsum <- eda_lsum( eda_re(mtcars$hp,i) ,l=5)   with(lsum, dotchart(x=mid, labels=letter, pt.cex=1.5,                       pch=20,main=paste(\"power=\",i)) ) } par(OP)"},{"path":"/articles/Introduction.html","id":"eda_sl","dir":"Articles","previous_headings":"","what":"eda_sl","title":"Introduction to EDA functions","text":"Usage: spread-level function generates spread-level table univariate dataset. pits log spread (range upper lower fourths default) vs. log median values across groups. function useful assessing monotonically increasing decreasing spread function median. Note function require values positive. following example shows sepal length spread increases increasing sepal length.","code":"eda_sl(dat, x, y) sl <- eda_sl(iris, Species, Sepal.Length) plot(spread ~ level, sl, pch=16)"},{"path":"/articles/Introduction.html","id":"eda_lm","dir":"Articles","previous_headings":"","what":"eda_lm","title":"Introduction to EDA functions","text":"Usage: eda_lm generates scatter plot. also superimposes least squares regression line , requested, LOESS curve. example,  scatter plot axes scaled respective standard deviations (displayed grey dashed lines) match length. dark grey solid lines show means variables. \\(X\\) \\(Y\\) labels can customized via x.lab y.lab parameters. label split across two lines, use \\n special character.  display regression summary statistics, set stats TRUE.  LOESS curve desired, set loe TRUE:  colors regression line LOESS curve can modified adjusting lm.col loe.col parameters follows:  Additional parameters can passed plot loess.smooth sub-functions via plot.d loess.d lists follows:","code":"eda_lm(dat, x, y, x.lab = \"X\", y.lab = \"Y\", reg = TRUE, rob=FALSE, loe = FALSE,          lm.col = rgb(1, 0.5, 0.5, 0.8), loe.col = rgb(.73, .73, 1, 1),          stats=FALSE,..., plot.d=NULL, loess.d=NULL) eda_lm(dat=cars, x=dist, y=speed) eda_lm(dat=cars, x=dist, y=speed, x.lab=\"Stopping Distance (ft)\", y.lab=\"Speed\\n(mph)\") eda_lm(dat=cars, x=dist, y=speed, stats = TRUE) eda_lm(dat=cars, x=dist, y=speed, loe=TRUE) eda_lm(dat=cars, x=dist, y=speed, loe=TRUE, lm.col=\"blue\", loe.col=rgb(1,0,0,0.3)) eda_lm(dat=cars, x=dist, y=speed, loe=TRUE, plot.d = list(pch=21, col=\"red\",bg=\"bisque\"),          loess.d=list( span=2/5), reg=FALSE)"},{"path":"/articles/Introduction.html","id":"eda_3pt","dir":"Articles","previous_headings":"","what":"eda_3pt","title":"Introduction to EDA functions","text":"Usage: eda_3pt generate scatter plot two variables. also generate three-point summary dividing dataset three approximately equal groups (based \\(x\\) values) summarize groups computing respective medians. Two half-slopes used join three points. Note matching \\(x\\) values lumped batch can lead unequal group sizes. motivation behind plot use three-point summary provide robust assessment type relationship variables. plots often used help guide re-expression variables \\(x\\) \\(y\\) sole purpose straightening \\(x\\)-\\(y\\) relationship. example, explore relationship stopping distance speed can generate following plot.  red points represent summary locations group, red solid lines half-slopes, grey solid slope linking tail-end groups used help assess straightness half-slopes. vertical dashed lines delineate three groups; points falling line belong group left. function also returns list. ratio half-slopes stored hsrtio component (e.g. pt3$hsrtio). closer ratio one, straighter relationship. example, ratio 1.611. default, function displays suggested direction re-expression along ladder powers (blue text plot). direction suggests variable transformed using higher powers \\(x^2\\) \\(x^3\\). direction suggests variable transformed using lower powers \\(\\sqrt{x}\\) \\(log(x)\\). suggested directions re-expression desired, set parameter dir=FALSE. Continuing example, may choose square speed. , ’ll use eda_re() function apply Tukey power transformation speed values. ’ll also customize x-axis label indicating x-values squared.  transformation better job aligning two half-slopes. half-slopes ratio (pt3b$hsrtio) 1.101 improvement original half-slopes ratio. Note instead transforming x-values, transformed y-values. example, taken cube root breaking distance follows:  seems even bigger improvement last re-expression half-slopes ratio 1.043.","code":"eda_3pt(dat, x, y, x.lab = \"X\", y.lab = \"Y\", adj = -.12, dir = TRUE, ...) pt3 <- eda_3pt(dat=cars, x=speed, y=dist) pt3b <- eda_3pt(dat=cars, x=eda_re(speed,2), y=dist,                 x.lab = expression(\"Speed\"^{2}) ) pt3c <- eda_3pt(dat=cars, x=speed, y=eda_re(dist,1/3),                 y.lab = expression(\"Distance\"^{3}) )"},{"path":"/articles/Introduction.html","id":"eda_unipow","dir":"Articles","previous_headings":"","what":"eda_unipow","title":"Introduction to EDA functions","text":"Usage: eda_unipow generates matrix histograms boxplots various re-expressions data x. values re-expressed using either Tukey power transformation (default) Box-Cox transformation (see eda_re information transformation techniques). default ladder powers consists 2, 1, 0.5, 0.33, 0, -.33, -0.5, -1, -2 power 0 substituted \\(log\\) function. Note power \\(1\\) gives raw (original) data.  mindful input values since re-expressions may work log(0). example, re-expressing yearly number sunspots using default ladder powers generates following error. sunspot.year three 0 values. values generate either -Inf log transformed Inf raised negative number (e.g. 0^(-0.33)). remedy , can either remove problematic values, adjust ladder powers. E.g.,  Since relatively large dataset, can increase number bins follows:  Note might need reset plotting device typing dev.() encounter difficulty generating plots executing eda_unipow function.","code":"eda_unipow(x, p = c(2, 1, 1/2, 0.33, 0, -0.33, -1/2, -1, -2), tukey=TRUE, bins=5,           cex.main=1.3, col=\"#DDDDDD\",border=\"#AAAAAA\",          title=\"Re-expressed data via ladder of powers\", ...) eda_unipow(mtcars$mpg, bins=6) eda_unipow(sunspot.year) #>  Error in eda_unipow(sunspot.year):  #>  One or more values did not return a valid #>  re-expression. For example, a value of 0 will #>  return an error if a log transformation is chosen. table(sunspot.year == 0) #>   #>  FALSE  TRUE  #>    286     3 eda_unipow(sunspot.year, p = c(2, 1, 1/2, 0.33)) eda_unipow(sunspot.year, p = c(2, 1, 1/2, 0.33), bin=15)"},{"path":"/articles/Introduction.html","id":"eda_bipow","dir":"Articles","previous_headings":"","what":"eda_bipow","title":"Introduction to EDA functions","text":"Usage: eda_bipow generates matrix scatter plots boxplots various re-expressions \\(x\\) \\(y\\) values. 3-point summary associated half-slopes also plotted (function makes use eda_3pt function). values re-expressed using either Tukey power transformation (default) Box-Cox transformation (see eda_re information transformation techniques). default ladder powers consists 3, 2, 1, .5, 0 power 0 substituted \\(log\\) function. Note power \\(1\\) gives raw (original) data. example, following line code displays bivariate relationship stopping distance speed using different ladder powers.  Notice medians boxplot match middle summary point (red) \\(x\\) \\(y\\) values–expected.","code":"eda_bipow(dat, x, y, p = c(3, 2, 1, .5, 0), tukey = TRUE, ...) eda_bipow(dat = cars, x = speed, y = dist)"},{"path":"/articles/Introduction.html","id":"eda_rline","dir":"Articles","previous_headings":"","what":"eda_rline","title":"Introduction to EDA functions","text":"Usage: detailed discussion resistant line, see accompanying vignette.","code":"eda_rline(dat, x, y)"},{"path":"/articles/Introduction.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Introduction to EDA functions","text":"Applications, Basics Computing Exploratory Data Analysis, P.F. Velleman D.C. Hoaglin, 1981. Understanding robust exploratory data analysis, D.C. Hoaglin, F. Mosteller J.W. Tukey, 1983. Exploratory Data Analysis, John Tukey, 1977.","code":""},{"path":"/articles/polish.html","id":"the-median-polish-basics","dir":"Articles","previous_headings":"","what":"The median polish basics","title":"Median polish","text":"median polish exploratory technique used extract effects two-way table. , median polish can thought robust version two-way ANOVA; goal characterize role factor contributing towards expected value. iteratively extracting effects associated row column factors via medians. example, given two-way table 1964 1966 infant mortality rates1 (reported count per 1000 live births) computed combination geographic region (NE, NC, S, W) level father’s educational attainment (ed8, ed9-11, ed12, ed13-15, ed16), median polish first extract overall median value, smooth residual rates first extracting median values along column (thus contributing column factor), smooth remaining residual rates extracting median values along row (thus contributing row factor). smoothing operation iterated residuals stabilize. workflow highlighted following figure.  left-table original data showing death rates. second table shows outcome first round polishing (including initial overall median value 20.2). third forth table show second third iterations smoothing operations. Additional iterations deemed necessary given little can extracted residuals. detailed step--step explanation workflow see . resulting model additive form : \\[ y_{ij} = \\mu + \\alpha_{} + \\beta_{j} +\\epsilon_{ij} \\] \\(y_{ij}\\) response variable row \\(\\) column \\(j\\), \\(\\mu\\) overall typical value (hereafter referred common value),\\(\\alpha_{}\\) row effect, \\(\\beta_{j}\\) column effect \\(\\epsilon_{ij}\\) residual value left effects taken account. factor’s effect displayed top row left-column. example, region assigned rows father’s educational attainment assigned columns. father’s educational attainment can explain 11 units variability (7.58 - (-3.45)) death rates vs 4 units variability region (2.55 - (-1.5)). , father’s educational attainment larger contributor expected infant mortality regional effect.","code":""},{"path":"/articles/polish.html","id":"implementing-the-median-polish","dir":"Articles","previous_headings":"","what":"Implementing the median polish","title":"Median polish","text":"package’s eda_polish augmented version built-medpolish available via stats package. key difference eda_polish takes input dataset long form opposed medpolish takes dataset form matrix. example, infant mortality dataset needs consist least three columns: one variable (two factors expected value). median polish can executed follows:  function output table plot along list components stored M1 object. want suppress plot, can set parameter plot = FALSE. M1 object class eda_polish. can extract common values, row column effects follows:","code":"grd <- c(\"ed8\", \"ed9-11\", \"ed12\", \"ed13-15\", \"ed16\") dat <- data.frame(region =  rep( c(\"NE\", \"NC\", \"S\", \"W\"), each = 5),                   edu = factor(rep( grd , 4), levels = grd),                   perc = c(25.3, 25.3, 18.2, 18.3, 16.3, 32.1, 29, 18.8,                            24.3, 19, 38.8, 31, 19.3, 15.7, 16.8, 25.4,                             21.1, 20.3, 24, 17.5)) head(dat)     region     edu perc   1     NE     ed8 25.3   2     NE  ed9-11 25.3   3     NE    ed12 18.2   4     NE ed13-15 18.3   5     NE    ed16 16.3   6     NC     ed8 32.1 library(tukeyedar) M1 <- eda_pol(dat, row = \"region\", col = \"edu\", val = \"perc\") M1$global   [1] 20.85 M1$row     region  effect   1     NC  2.3000   2     NE -1.4625   3      S -0.3500   4      W  0.3500 M1$col         edu   effect   1     ed8  7.43125   2  ed9-11  5.88125   3    ed12 -1.19375   4 ed13-15  0.03125   5    ed16 -3.70000"},{"path":"/articles/polish.html","id":"ordering-rows-and-columns-by-effect-values","dir":"Articles","previous_headings":"Implementing the median polish","what":"Ordering rows and columns by effect values","title":"Median polish","text":"order row column effects effect values, set sort parameter TRUE.","code":"M1 <- eda_pol(dat, row = \"region\", col = \"edu\", val = \"perc\", sort = TRUE)"},{"path":"/articles/polish.html","id":"applying-a-transformation-to-the-data","dir":"Articles","previous_headings":"Implementing the median polish","what":"Applying a transformation to the data","title":"Median polish","text":"can function re-express values prior performing polish. example, log transform data, pass value 0 p.  re-expressing data using negative power, choice adopting Tukey transformation (tukey = TRUE) Box-Cox transformation (tukey = FALSE). example, apply power transfromation -0.1 using Box-Cox transformation, type:","code":"M1 <- eda_pol(dat, row = \"region\", col = \"edu\", val = \"perc\", p = 0) M1 <- eda_pol(dat, row = \"region\", col = \"edu\", val = \"perc\", p = -0.1, tukey = FALSE)"},{"path":"/articles/polish.html","id":"defining-the-statistic","dir":"Articles","previous_headings":"Implementing the median polish","what":"Defining the statistic","title":"Median polish","text":"default, polishing routine adopts median statistic. can adopt statistic via stat parameter. example, apply mean polish, type:  familiar two-way ANOVA, ’ll note computed effects mean polish match computed two-way ANOVA:","code":"M1 <- eda_pol(dat, row = \"region\", col = \"edu\", val = \"perc\", stat = mean) model.tables(aov(perc ~ region + edu, dat))   Tables of effects       region    region       NC     NE      S      W     1.815 -2.145  1.495 -1.165        edu    edu       ed8  ed9-11    ed12 ed13-15    ed16      7.575   3.775  -3.675  -2.250  -5.425"},{"path":"/articles/polish.html","id":"the-eda_polish-plot-method","dir":"Articles","previous_headings":"","what":"The eda_polish plot method","title":"Median polish","text":"list opbject created eda_pol function class eda_polish. , plot method created class. plot method either output original polished table (type = \"residuals\"), diagnostic plot (type = \"diagnostic\"), CV values (cv).","code":""},{"path":"/articles/polish.html","id":"plot-the-median-polish-table","dir":"Articles","previous_headings":"","what":"Plot the median polish table","title":"Median polish","text":"can generate plot table median polish model follows:","code":"M1 <- eda_pol(dat, row = \"region\", col = \"edu\", val = \"perc\", plot = FALSE) plot(M1)"},{"path":[]},{"path":"/articles/polish.html","id":"removing-common-effect-from-color-palette-range","dir":"Articles","previous_headings":"Adjusting color schemes","what":"Removing common effect from color palette range","title":"Median polish","text":"default, range color palettes defined range values table. includes common value. prevent common value affecting distribution color palettes, set col.com FALSE.  Note distribution colors maximized help improve view effects. view makes clear father’s educational attainment greate effect region.","code":"plot(M1, col.com = FALSE)"},{"path":"/articles/polish.html","id":"removing-rowcolumn-effects-from-color-palette-range","dir":"Articles","previous_headings":"Adjusting color schemes","what":"Removing row/column effects from color palette range","title":"Median polish","text":"want plot focus residuals maximizing range colors fit range residual values, set col.eff = FALSE.  Note setting col.eff FALSE prevent effects cells colored. simply ensures range colors maximized match full range residual values. effect value falls within residual range assigned color.","code":"plot(M1, col.eff = FALSE)"},{"path":"/articles/polish.html","id":"changing-color-schemes","dir":"Articles","previous_headings":"Adjusting color schemes","what":"changing color schemes","title":"Median polish","text":"default, color scheme symmetrical centered 0. adopts R (version 4.1 ) built-\"RdYlBu\" color palettes. can assign different built-color palettes via colpal parameter. can list available colors via hcl.pals() function. want limit output divergent color palettes, type: example, can assign \"Green-Brown\" color palette follows. (’ll remove common value range input values maximize displayed set colors).  default classification scheme symmetrical linear, centered 0. want maximize use colors, reagrdless range values, can set col.quant TRUE.  ’ll note regardless asymmetrical distribution values 0, cell assigned unique color swatch. adopting quantitative color classification scheme, might want adopt color palette generates fewer unique hues variation lightness values. example,","code":"hcl.pals(type = \"diverging\")    [1] \"Blue-Red\"      \"Blue-Red 2\"    \"Blue-Red 3\"    \"Red-Green\"        [5] \"Purple-Green\"  \"Purple-Brown\"  \"Green-Brown\"   \"Blue-Yellow 2\"    [9] \"Blue-Yellow 3\" \"Green-Orange\"  \"Cyan-Magenta\"  \"Tropic\"          [13] \"Broc\"          \"Cork\"          \"Vik\"           \"Berlin\"          [17] \"Lisbon\"        \"Tofino\" plot(M1, colpal = \"Green-Brown\", col.com = FALSE) plot(M1, col.quant = TRUE) plot(M1, col.quant = TRUE, colpal = \"Green-Orange\")"},{"path":"/articles/polish.html","id":"adjusting-text","dir":"Articles","previous_headings":"","what":"Adjusting text","title":"Median polish","text":"can omit labeled values output setting res.txt FALSE.  Likewise can omit axes labels setting label.txt FALSE. may prove useful applying median polish large grid file.  can adjust text size via res.size, row.size col.size parameters value labels (effects residuals), row names, column names respectively. example, set sizes 50% default value type:","code":"plot(M1, res.txt = FALSE) plot(M1, res.txt = FALSE, label.txt = FALSE) plot(M1, row.size = 0.6, col.size = 0.6 , res.size = 0.6)"},{"path":"/articles/polish.html","id":"exploring-diagnostic-plots","dir":"Articles","previous_headings":"","what":"Exploring diagnostic plots","title":"Median polish","text":"plot method also generate diagnostic plot residuals vs comparison values (CV).  plot shows relationship CV values residuals. bisquare robust line fitted data (light red line) along robust loess fit (dashed blue line). function also output line’s slope. slope can used help estimate transformation data, needed. generate plot, simply extract cv component M1 list. cv component dataframe stores residuals (first column) CV values (fourth column). first records data frame shown next.","code":"plot(M1, type = \"diagnostic\") $slope         cv    4.515854 head(M1$cv)       perc    row    col         cv   1  2.315 -1.165 -3.675  0.1875739   2 -2.165  1.815 -3.675 -0.2922289   3 -1.345  1.495 -3.675 -0.2407065   4  1.195 -2.145 -3.675  0.3453614   5  1.910  1.815 -2.250 -0.1789157   6 -0.130 -2.145 -2.250  0.2114458"},{"path":"/articles/RLine.html","id":"the-resistant-line-basics","dir":"Articles","previous_headings":"","what":"The resistant line basics","title":"Resistant Line","text":"eda_rline function fits robust line bivariate dataset. first breaking data three roughly equal sized batches following x-axis variable. uses batches’ median values compute slope intercept. However, function doesn’t stop . fitting inital line, function fits another line (following aforementioned methodology) model’s residuals. slope close zero, residual slope added original fitted model creating updated model. iteration repeated residual slope close zero residual slope changes sign (point average last two iterated slopes used final fit). example iteration follows using data Velleman et. al’s book. dataset, neoplasms, consists breast cancer mortality rates regions varying mean annual temperatures.  three batches divided follows:  Note 16 record dataset divisible three thus forcing extra point middle batch (remainder division three two, extra point added tail-end batches). Next, compute medians batch (highlighted red points following figure).  two end medians used compute slope : \\[ b = \\frac{y_r - y_l}{x_r-x_l} \\] subscripts \\(r\\) \\(l\\) reference median values right-left-batches. slope computed, intercept can computed follows: \\[ median(y_{l,m,r} - b * x_{l,m,r}) \\] \\((x,y)_{l,m,r}\\) median x y values batch. line used compute first set residuals. line fitted residuals following procedure outlined .  initial model slope intercept 3.412 -69.877 respectively residual’s slope intercept -0.873 41.451 respectively. residual slope added first computed slope process repeated thus generating following tweaked slope updated residuals:  updated slope now 3.412 + (-0.873) = 2.539. iteration continues slope residuals stabilize. final line working example ,  final slope intercept 2.89 -45.91, respectively.","code":""},{"path":"/articles/RLine.html","id":"implementing-the-resistant-line","dir":"Articles","previous_headings":"","what":"Implementing the resistant line","title":"Resistant Line","text":"eda_rline takes just three arguments: data frame, x variable y variable. function output list. elements b model’s intercept slope. vectors x y input values sorted x. res vector final residuals sorted x. xmed ymed vectors medians three batches. can use output values generate following plot.  wish add median values three batches reference, modify code follows:  see resistant line compares ordinary least-squares (OLS) regression slope, type:  regression model computes slope 2.36 whereas resistant line function generates slope 2.89. scatter plot, can spot point may undo influence regression line (point highlighted green following plot).  Removing point data generates OLS regression line inline resistant model. point interest 15th record neoplasms data frame.","code":"M <- eda_rline(neoplasms, Temp, Mortality) M #>  $b #>  [1] 2.890173 #>   #>  $a #>  [1] -45.90578 #>   #>  $res #>   [1]  21.2982659   0.1398844  -2.1791908   8.8294798 -11.2485549  -7.6167630 #>   [7]  -0.1398844   4.7589595  -9.0092486  -2.1994220   2.7554913  -7.2676301 #>  [13]  -0.3907514   6.1861272   1.7971098   0.1398844 #>   #>  $x #>   [1] 31.8 34.0 40.2 42.1 42.3 43.5 44.2 45.1 46.3 47.3 47.8 48.5 49.2 49.9 50.0 #>  [16] 51.3 #>   #>  $y #>   [1]  67.3  52.5  68.1  84.6  65.1  72.2  81.7  89.2  78.9  88.6  95.0  87.0 #>  [13]  95.9 104.5 100.4 102.5 #>   #>  $xmed #>  [1] 40.2 45.7 49.9 #>   #>  $ymed #>  [1]  67.30  85.15 100.40 #>   #>  $index #>  [1]  5 11 16 plot(Mortality~Temp, neoplasms, pch=20) abline(a=M$a, b=M$b, col=rgb(1,0,0,0.5)) plot(Mortality~Temp, neoplasms, pch=20) abline(a=M$a, b=M$b, col=rgb(1,0,0,0.5)) points(x=M$xmed, y=M$ymed, col=rgb(1,0,0,0.5), pch=20,cex=2) plot(Mortality~Temp, neoplasms, pch=20) abline(a=M$a, b=M$b, col=rgb(1,0,0,0.5)) abline(lm(Mortality~Temp, neoplasms),lty=2) # Regression model plot(Mortality~Temp, neoplasms, pch=20) abline(a=M$a, b=M$b, col=rgb(1,0,0,0.5)) abline(lm(Mortality~Temp, neoplasms),lty=2) # Regression model points(neoplasms[15,], col=\"#43CD80\",cex=2 ,pch=20) neoplasms.sub <- neoplasms[-15,] plot(Mortality~Temp, neoplasms, pch=20) abline(a=M$a, b=M$b, col=rgb(1,0,0,0.5)) abline(lm(Mortality~Temp, neoplasms.sub),lty=2) # Regression model with data subset points(neoplasms[15,], col=\"#43CD80\",cex=2 ,pch=20)"},{"path":[]},{"path":"/articles/RLine.html","id":"nine-point-data","dir":"Articles","previous_headings":"Other examples","what":"Nine point data","title":"Resistant Line","text":"nine_point dataset used Hoaglin et. al (p. 139) test resistant line function’s ability stabilize wild oscillations computed slopes across iterations.  , slope intercept 0.067 0.133 respectively matching 1/15 2/15 values computed Hoaglin et. al.","code":"M <- eda_rline(nine_point, X,Y) plot(Y~X, nine_point, pch=20) abline(a=M$a, b=M$b, col=rgb(1,0,0,0.5))"},{"path":"/articles/RLine.html","id":"age-vs--height-data","dir":"Articles","previous_headings":"Other examples","what":"Age vs. height data","title":"Resistant Line","text":"age_height another dataset pulled Hoaglin et. al (p. 135). gives ages heights children private urban school.  , slope intercept 0.429 91.007 respectively matching 0.426 slope closely matching 90.366 intercept values computed Hoaglin et. al page 137.","code":"M <- eda_rline(age_height, Months,Height) plot(Height ~ Months, age_height, pch=20) abline(a=M$a, b=M$b, col=rgb(1,0,0,0.5))"},{"path":"/articles/RLine.html","id":"not-all-relationships-are-linear","dir":"Articles","previous_headings":"","what":"Not all relationships are linear!","title":"Resistant Line","text":"’s important remember resistant line technique valid bivariate relationship linear. , ’ll step example highlighted Velleman et. al (p. 138) using R built-mtcars dataset. First, ’ll fit resistant line data.  ’s important note just resistant line can fit necessarily imply relationship linear. assess linearity mtcars dataset, ’ll make use eda_3pt function (see accompanying vignette details interpreting 3-point summary function).  ’s clear two half slopes relationship linear. Velleman et. al first suggest re-expressing mpg 1/mpg giving us number gallons consumed per mile driven.  improvement, however two half slopes still differ significantly. therefore opt re-express disp variable. One possibility take inverse 1/3 since displacement measure volume (e.g. length3) gives us:  Now identified re-expressions linearise relationship, can fit resistant line. (Note grey line generated eda_3pt function resistant line generated eda_rline.)","code":"M <- eda_rline(mtcars, disp, mpg) plot(mpg ~ disp, mtcars, pch=20) abline(a=M$a, b=M$b, col=rgb(1,0,0,0.5)) eda_3pt(mtcars, disp, mpg) eda_3pt(mtcars, disp, 1/mpg, y.lab = \"gal/mi\") eda_3pt(mtcars, disp^(-1/3), 1/mpg,          y.lab = \"gal/mi\",         x.lab = expression(\"Displacement\"^{-1/3})) M <- eda_rline(mtcars, disp^(-1/3), 1/mpg) plot(1/mpg ~ eval(disp^(-1/3)), mtcars, pch=20,      ylab = \"gal/mi\",      xlab = expression(\"Displacement\"^{-1/3})) abline(a=M$a, b=M$b, col=rgb(1,0,0,0.5))"},{"path":"/articles/RLine.html","id":"computing-a-confidence-interval","dir":"Articles","previous_headings":"","what":"Computing a confidence interval","title":"Resistant Line","text":"Confidence intervals coefficients can estimated using bootstrapping techniques. two approaches: resampling residuals resampling x-y cases.","code":""},{"path":"/articles/RLine.html","id":"resampling-the-model-residuals","dir":"Articles","previous_headings":"Computing a confidence interval","what":"Resampling the model residuals","title":"Resistant Line","text":", fit resistant line extract residuals. re-run model many times replacing original y values modeled y values plus resampled residuals generate confidence intervals. Now plot distributions,  tabulate 95% confidence interval.","code":"n  <- 599 # Set number of iterations M  <- eda_rline(neoplasms, Temp, Mortality) # Fit the resistant line bt <- array(0, dim=c(n, 2)) # Create empty bootstrap array for(i in 1:n){ #bootstrap loop   df.bt <- data.frame(x=M$x, y = M$y +sample(M$res,replace=TRUE))   bt[i,1] <- eda_rline(df.bt,x,y)$a   bt[i,2] <- eda_rline(df.bt,x,y)$b } hist(bt[,1], main=\"Intercept distribution\") hist(bt[,2], main=\"Slope distribution\") conf <- t(data.frame(Intercept = quantile(bt[,1], p=c(0.05,0.95) ),                      Slope = quantile(bt[,2], p=c(0.05,0.95) ))) conf #>                    5%      95% #>  Intercept -78.943629 8.098680 #>  Slope       1.764128 3.569992"},{"path":"/articles/RLine.html","id":"resampling-the-x-y-paired-values","dir":"Articles","previous_headings":"Computing a confidence interval","what":"Resampling the x-y paired values","title":"Resistant Line","text":", resample x-y paired values (replacement) compute resistant line time. Now plot distributions,  tabulate 95% confidence interval.","code":"n  <- 599 # Set number of iterations bt <- array(0, dim=c(n, 2)) # Create empty bootstrap array for(i in 1:n){ #bootstrap loop   recs <- sample(1:nrow(neoplasms), replace = TRUE)   df.bt <- neoplasms[recs,]   bt[i,1]=eda_rline(df.bt,Temp,Mortality)$a   bt[i,2]=eda_rline(df.bt,Temp,Mortality)$b } hist(bt[,1], main=\"Intercept distribution\") hist(bt[,2], main=\"Slope distribution\") conf <- t(data.frame(Intercept = quantile(bt[,1], p=c(0.05,0.95) ),                      Slope = quantile(bt[,2], p=c(0.05,0.95) ))) conf #>                     5%       95% #>  Intercept -108.869579 15.031034 #>  Slope        1.642725  4.180929"},{"path":"/articles/RLine.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Resistant Line","text":"Applications, Basics Computing Exploratory Data Analysis, P.F. Velleman D.C. Hoaglin, 1981. Understanding robust exploratory data analysis, D.C. Hoaglin, F. Mosteller J.W. Tukey, 1983.","code":""},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Manuel Gimond. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"text","code":"@Misc{,   title = {tukeyedar: A package of Tukey inspired EDA functions},   author = {Manuel Gimond},   url = {https://mgimond.github.io/tukeyedar/},   year = {2021}, }"},{"path":"/index.html","id":"tukeyedar","dir":"","previous_headings":"","what":"Tukey Inspired Exploratory Data Analysis Functions","title":"Tukey Inspired Exploratory Data Analysis Functions","text":"tukeyedar package houses subset functions used Exploratory Data Analysis (EDA). functions inspired work published Tukey (1977), D. C. Hoaglin Tukey (1983) Velleman Hoaglin (1981). Note package beta mode, use discretion. Many plots generated functions necessarily geared publication designed focus viewer’s attention patterns generated plots (hence reason light colored axes missing axes labels plots ).","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Tukey Inspired Exploratory Data Analysis Functions","text":"package can installed github (installation process makes use devtools package). Note vignettes automatically generated command; note vignettes available website (see next section). want local version vignettes, add build_vignettes = TRUE parameter. vignette require dplyr installed since eda_sl function relies . dplyr already installed, aforementioned syntax automatically install . reason vignettes created, might want re-install package force=TRUE parameter.","code":"devtools::install_github(\"mgimond/tukeyedar\") devtools::install_github(\"mgimond/tukeyedar\", build_vignettes = TRUE) devtools::install_github(\"mgimond/tukeyedar\", build_vignettes = TRUE, force=TRUE)"},{"path":"/index.html","id":"read-the-vignettes","dir":"","previous_headings":"","what":"Read the vignettes!","title":"Tukey Inspired Exploratory Data Analysis Functions","text":"’s strongly recommended read vignettes. can accessed website: introduction functions detailed rundown resistant line function chose vignettes locally created installed package, can view locally via vignette(\"Introduction\", package = \"tukeyedar\") vignette(\"RLine\", package = \"tukeyedar\"). use dark themed IDE, vignettes may render well might opt view web browser via functions RShowDoc(\"Introduction\", package = \"tukeyedar\") RShowDoc(\"RLine\", package = \"tukeyedar\").","code":""},{"path":"/index.html","id":"using-the-functions","dir":"","previous_headings":"","what":"Using the functions","title":"Tukey Inspired Exploratory Data Analysis Functions","text":"functions start eda_. example, generate three point summary plot mpg vs. disp mtcars dataset, type: Note functions pipe friendly. example:","code":"library(tukeyedar) eda_3pt(mtcars, disp, mpg) # Using R >= 4.1 mtcars |>  eda_3pt(disp, mpg)  # Using magrittr (or any of the tidyverse packages) library(magrittr) mtcars %>% eda_3pt(disp, mpg)"},{"path":"/reference/age_height.html","id":null,"dir":"Reference","previous_headings":"","what":"Age vs. height for private and rural school children — age_height","title":"Age vs. height for private and rural school children — age_height","text":"data reproduced Hoaglin et al.'s book  originally sourced Bernard G. Greenberg (1953) American Journal Public Health (vol 43, pp. 692-699). dataset tabulate children's height weight urban private rural public schools.","code":""},{"path":"/reference/age_height.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Age vs. height for private and rural school children — age_height","text":"","code":"age_height"},{"path":"/reference/age_height.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Age vs. height for private and rural school children — age_height","text":"data frame 18 rows 2 variables: Months Child's age months Height Child's height cm","code":""},{"path":"/reference/age_height.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Age vs. height for private and rural school children — age_height","text":"Understanding robust exploratory data analysis, D.C. Hoaglin,    F. Mosteller J.W. Tukey. (page 135)","code":""},{"path":"/reference/eda_3pt.html","id":null,"dir":"Reference","previous_headings":"","what":"3-point summary plot — eda_3pt","title":"3-point summary plot — eda_3pt","text":"eda_3pt splits data 3 groups (whose summary locations  defined respective medians), two half slopes linking groups.  function return scatter plot showing half-slopes red  solid lines. solid grey slope linking tail-end groups shows  desired shape half-slopes. goal two halve slopes  line closely possible solid grey slope via re-expression techniques  seeking linear relationship variables. function also return  half-slopes ratio hsrtio direction re-expression  X Y values ladder powers.","code":""},{"path":"/reference/eda_3pt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"3-point summary plot — eda_3pt","text":"","code":"eda_3pt(   dat,   x,   y,   x.lab = NULL,   y.lab = NULL,   adj = -0.12,   dir = TRUE,   pch = 20,   col = \"grey40\",   ... )"},{"path":"/reference/eda_3pt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"3-point summary plot — eda_3pt","text":"dat Data frame x Column name assigned x axis y Column name assigned y axis x.lab X label output plot y.lab Y label output plot adj Adjustment parameter y label dir Boolean indicating suggested ladder power direction displayed pch Plot point size fraction (can larger 1.0) col Plot point color ... parameters passed graphics::plot function.","code":""},{"path":"/reference/eda_3pt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"3-point summary plot — eda_3pt","text":"Outputs plot showing three point summary well list parameters: hsrtio: ratio slopes. value close one   suggests transformation needed. xmed: x-coordinate values three summary points. ymed: y-coordinate values three summary points.","code":""},{"path":"/reference/eda_3pt.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"3-point summary plot — eda_3pt","text":"Velleman, P. F., D. C. Hoaglin. 1981. Applications, Basics Computing Exploratory Data Analysis. Boston: Duxbury Press. D. C. Hoaglin, F. Mosteller, J. W. Tukey. 1983. Understanding Robust Exploratory Data Analysis. Wiley. Tukey, John W. 1977. Exploratory Data Analysis. Addison-Wesley.","code":""},{"path":"/reference/eda_3pt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"3-point summary plot — eda_3pt","text":"","code":"hsratio <- eda_3pt(cars, speed, dist)  hsratio <- eda_3pt(cars, speed, dist^(1/3), y.lab=expression(\"Dist\"^{1/3}), adj=-0.1)"},{"path":"/reference/eda_bipow.html","id":null,"dir":"Reference","previous_headings":"","what":"Ladder of powers transformation on bivariate data with three-point summary plot — eda_bipow","title":"Ladder of powers transformation on bivariate data with three-point summary plot — eda_bipow","text":"Re-expresses vector ladder powers.  Requires eda_3pt() function.","code":""},{"path":"/reference/eda_bipow.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ladder of powers transformation on bivariate data with three-point summary plot — eda_bipow","text":"","code":"eda_bipow(dat, x, y, p = c(3, 2, 1, 0.5, 0), tukey = TRUE, ...)"},{"path":"/reference/eda_bipow.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ladder of powers transformation on bivariate data with three-point summary plot — eda_bipow","text":"dat Data frame x Column name assigned x axis y Column name assigned y axis p Vector powers tukey set TRUE, adopt Tukey's power transformation. FALSE, adopt Box-Cox transformation. ... parameters passed graphics::plot function.","code":""},{"path":"/reference/eda_bipow.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Ladder of powers transformation on bivariate data with three-point summary plot — eda_bipow","text":"Generates matrix scatter plots boxplots various re-expressions x y values. 3-point summary associated half-slopes also plotted (function makes use eda_3pt function). values re-expressed using either Tukey power transformation (default) Box-Cox transformation (see eda_re information transformation techniques). Axes labels omitted reduce plot clutter.","code":""},{"path":"/reference/eda_bipow.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Ladder of powers transformation on bivariate data with three-point summary plot — eda_bipow","text":"Tukey, John W. 1977. Exploratory Data Analysis. Addison-Wesley.","code":""},{"path":"/reference/eda_bipow.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ladder of powers transformation on bivariate data with three-point summary plot — eda_bipow","text":"","code":"eda_bipow(dat = cars, x = speed, y = dist)"},{"path":"/reference/eda_boxls.html","id":null,"dir":"Reference","previous_headings":"","what":"Create boxplots equalized by level and spread — eda_boxls","title":"Create boxplots equalized by level and spread — eda_boxls","text":"eda_boxls creates boxplots conditioned one variable providing option equalize levels /spreads.","code":""},{"path":"/reference/eda_boxls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create boxplots equalized by level and spread — eda_boxls","text":"","code":"eda_boxls(   dat,   x,   fac,   outlier = TRUE,   out.txt,   type = \"l\",   horiz = FALSE,   outliers = TRUE )"},{"path":"/reference/eda_boxls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create boxplots equalized by level and spread — eda_boxls","text":"dat Data frame x Column name assigned values fac Column name assigned factor values conditioned outlier Boolean indicating outliers plotted .txt Column whose values used label outliers type Plot type. \"none\" = equalization ; \"l\" = equalize level; \"ls\" = equalize level spread horiz plot horizontally (TRUE) vertically (FALSE) outliers plot outliers (TRUE) (FALSE)","code":""},{"path":"/reference/eda_boxls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create boxplots equalized by level and spread — eda_boxls","text":"","code":"# A basic boxplot (no equalization) eda_boxls(mtcars,mpg, cyl, type=\"none\", out.txt=mpg )   # Boxplots equalized by level eda_boxls(mtcars,mpg, cyl, type=\"l\", out.txt=mpg )   # Boxplots equalized by level and spread eda_boxls(mtcars,mpg, cyl, type=\"ls\", out.txt=mpg )   # Hide outlier eda_boxls(mtcars,mpg, cyl, type=\"ls\", out.txt=mpg , outlier=FALSE)"},{"path":"/reference/eda_lm.html","id":null,"dir":"Reference","previous_headings":"","what":"Least Squares regression plot (with optional LOESS fit) — eda_lm","title":"Least Squares regression plot (with optional LOESS fit) — eda_lm","text":"eda_lm generates scatter plot fitted regression line.  loess line can  also added plot  model comparison. axes scaled respective  standard  deviations match axes unit length.","code":""},{"path":"/reference/eda_lm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Least Squares regression plot (with optional LOESS fit) — eda_lm","text":"","code":"eda_lm(   dat,   x,   y,   x.lab = NULL,   y.lab = NULL,   reg = TRUE,   loe = FALSE,   lm.col = rgb(1, 0.5, 0.5, 0.8),   loe.col = rgb(0.73, 0.73, 1, 1),   stats = FALSE,   plot.d = list(pch = 20, col = \"grey40\"),   ...,   loess.d = NULL )"},{"path":"/reference/eda_lm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Least Squares regression plot (with optional LOESS fit) — eda_lm","text":"dat Data frame x Column assigned x axis y Column assigned y axis x.lab X label output plot y.lab Y label output plot reg Boolean indicating whether least squares regression line plotted loe Boolean indicating loess curve fitted lm.col Regression line color loe.col LOESS curve color stats Boolean indicating regression summary statistics displayed plot.d list parameters passed plot function ... used loess.d list parameters passed loess.smooth function","code":""},{"path":[]},{"path":"/reference/eda_lm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Least Squares regression plot (with optional LOESS fit) — eda_lm","text":"","code":"# Add a regular (OLS) regression model and loess smooth to the data eda_lm(mtcars, wt, mpg, plot.d = list(pch=16, col=\"blue\"), loe=TRUE)   # Modify the loess smooth by adopting a robust fit and adjusting its # span and polynomial order eda_lm(mtcars, wt, mpg, plot.d = list(pch=16, col=\"black\"), loe=TRUE,       loess.d=list(family = \"symmetric\", span=0.5, degree=2))"},{"path":"/reference/eda_lsum.html","id":null,"dir":"Reference","previous_headings":"","what":"Tukey's letter value summaries — eda_lsum","title":"Tukey's letter value summaries — eda_lsum","text":"eda_lsum letter value summary introduced John Tukey  extends boxplot's 5 number summary exploring symmetry  batch depth levels half (median)  fourth (quartiles).","code":""},{"path":"/reference/eda_lsum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tukey's letter value summaries — eda_lsum","text":"","code":"eda_lsum(x, l = 5, all = TRUE)"},{"path":"/reference/eda_lsum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tukey's letter value summaries — eda_lsum","text":"x Vector l Number levels (max = 9) Generate upper, lower mid summaries TRUE just generate mid summaries FALSE","code":""},{"path":"/reference/eda_lsum.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Tukey's letter value summaries — eda_lsum","text":"Outputs data frame letter value summaries.","code":""},{"path":"/reference/eda_lsum.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Tukey's letter value summaries — eda_lsum","text":"Exploratory Data Analysis, John Tukey, 1973.","code":""},{"path":[]},{"path":"/reference/eda_lsum.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tukey's letter value summaries — eda_lsum","text":"","code":"x <- c(22, 8, 11, 3, 26, 1, 14, 18, 20, 25, 24) eda_lsum(x) #>   letter depth lower   mid upper spread #> 1      M   6.0  18.0 18.00  18.0    0.0 #> 2      H   3.5   9.5 16.25  23.0   13.5 #> 3      E   2.0   3.0 14.00  25.0   22.0 #> 4      D   1.5   2.0 13.75  25.5   23.5 #> 5      C   1.0   1.0 13.50  26.0   25.0"},{"path":"/reference/eda_pol.html","id":null,"dir":"Reference","previous_headings":"","what":"Polish two-way tables — eda_pol","title":"Polish two-way tables — eda_pol","text":"eda_pol Polishes two-way tables using median, means, customizable functions.","code":""},{"path":"/reference/eda_pol.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Polish two-way tables — eda_pol","text":"","code":"eda_pol(   x,   row = NULL,   col = NULL,   val = NULL,   stat = median,   plot = TRUE,   eps = 0.01,   maxiter = 5,   sort = FALSE,   p = 1,   tukey = FALSE,   col.quant = FALSE,   colpal = \"RdYlBu\",   adj.mar = FALSE,   res.size = 1,   row.size = 1,   col.size = 1,   res.txt = TRUE,   label.txt = TRUE )"},{"path":"/reference/eda_pol.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Polish two-way tables — eda_pol","text":"x three column data frame row Name column assigned row effect col Name column assigned column effect val Name column assigned response variable stat Polishing statistic (default median) plot Boolean determining output plot generated eps Convergence tolerance parameter maxiter Maximum number iterations sort Boolean determining effects row/columns sorted p Re-expression power parameter tukey Boolean determining Tukey's power transformation used. FALSE, Box-Cox transformation adopted. col.quant Boolean determining quantile classification scheme used colpal Color palette adopt adj.mar Boolean determining margin width needs accomodate labels res.size Size residual values plot [0-1] row.size Size row effect values plot [0-1] col.size Size column effect values plot [0-1] res.txt Boolean determining values added plot label.txt Boolean determining margin column labels plotted","code":""},{"path":"/reference/eda_pol.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Polish two-way tables — eda_pol","text":"function performs polish two way table. default, applies  median polish, statistic mean can passed function  via stat =  parameter.  function returns list row/column effects along global residual values.  also generate colored table plot = TRUE.  Returns list class eda_polish","code":""},{"path":"/reference/eda_pol.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Polish two-way tables — eda_pol","text":"","code":"df <- data.frame(region =  rep( c(\"NE\", \"NC\", \"S\", \"W\"), each = 5), edu = rep( c(\"ed8\", \"ed9to11\", \"ed12\", \"ed13to15\", \"ed16\"), 4), perc = c(25.3, 25.3, 18.2, 18.3, 16.3, 32.1, 29, 18.8,         24.3, 19, 38.8, 31, 19.3, 15.7, 16.8, 25.4, 21.1, 20.3, 24, 17.5))  eda_pol(df, row = \"region\", col = \"edu\", val = \"perc\", plot = FALSE) #> $long #>         edu region     perc #> 1      ed12     NC -3.15625 #> 2      ed12     NE  0.00625 #> 3      ed12      W  0.29375 #> 4      ed12      S -0.00625 #> 5  ed13to15     NE -1.11875 #> 6  ed13to15      S -4.83125 #> 7  ed13to15     NC  1.11875 #> 8  ed13to15      W  2.76875 #> 9      ed16      S  0.00000 #> 10     ed16     NC -0.45000 #> 11     ed16      W  0.00000 #> 12     ed16     NE  0.61250 #> 13      ed8     NC  1.51875 #> 14      ed8     NE -1.51875 #> 15      ed8      S 10.86875 #> 16      ed8      W -3.23125 #> 17  ed9to11     NE  0.03125 #> 18  ed9to11     NC -0.03125 #> 19  ed9to11      S  4.61875 #> 20  ed9to11      W -5.98125 #>  #> $wide #>         eff     ed12 ed13to15    ed16      ed8  ed9to11 #> eff 20.8500 -1.19375  0.03125 -3.7000  7.43125  5.88125 #> NC   2.3000 -3.15625  1.11875 -0.4500  1.51875 -0.03125 #> NE  -1.4625  0.00625 -1.11875  0.6125 -1.51875  0.03125 #> S   -0.3500 -0.00625 -4.83125  0.0000 10.86875  4.61875 #> W    0.3500  0.29375  2.76875  0.0000 -3.23125 -5.98125 #>  #> $row #>   region  effect #> 1     NC  2.3000 #> 2     NE -1.4625 #> 3      S -0.3500 #> 4      W  0.3500 #>  #> $col #>        edu   effect #> 1     ed12 -1.19375 #> 2 ed13to15  0.03125 #> 3     ed16 -3.70000 #> 4      ed8  7.43125 #> 5  ed9to11  5.88125 #>  #> $global #> [1] 20.85 #>  #> $iter #> [1] 5 #>  #> $cv #>        perc     row      col            cv #> 1  -3.15625  2.3000 -1.19375 -0.1316846523 #> 2  -0.00625 -0.3500 -1.19375  0.0200389688 #> 3   0.00625 -1.4625 -1.19375  0.0837342626 #> 4   0.29375  0.3500 -1.19375 -0.0200389688 #> 5  -4.83125 -0.3500  0.03125 -0.0005245803 #> 6   1.11875  2.3000  0.03125  0.0034472422 #> 7   2.76875  0.3500  0.03125  0.0005245803 #> 8  -1.11875 -1.4625  0.03125 -0.0021919964 #> 9  -0.45000  2.3000 -3.70000 -0.4081534772 #> 10  0.61250 -1.4625 -3.70000  0.2595323741 #> 11  0.00000  0.3500 -3.70000 -0.0621103118 #> 12  0.00000 -0.3500 -3.70000  0.0621103118 #> 13 -1.51875 -1.4625  7.43125 -0.5212567446 #> 14 10.86875 -0.3500  7.43125 -0.1247452038 #> 15  1.51875  2.3000  7.43125  0.8197541966 #> 16 -3.23125  0.3500  7.43125  0.1247452038 #> 17 -0.03125  2.3000  5.88125  0.6487709832 #> 18  0.03125 -1.4625  5.88125 -0.4125337230 #> 19  4.61875 -0.3500  5.88125 -0.0987260192 #> 20 -5.98125  0.3500  5.88125  0.0987260192 #>  #> $power #> [1] 1 #>  #> $IQ_row #> [1] 0.4177057 #>  #> $IQ_col #> [1] 2.016388 #>  #> attr(,\"class\") #> [1] \"eda_polish\""},{"path":"/reference/eda_re.html","id":null,"dir":"Reference","previous_headings":"","what":"Re-expression function — eda_re","title":"Re-expression function — eda_re","text":"eda_re re-expresses vector following Tukey box-cox transformation.","code":""},{"path":"/reference/eda_re.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Re-expression function — eda_re","text":"","code":"eda_re(x, p = 0, tukey = TRUE)"},{"path":"/reference/eda_re.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Re-expression function — eda_re","text":"x Vector p Power transformation tukey set TRUE, adopt Tukey's power transformation, FALSE, adopt Box-Cox transformation","code":""},{"path":"/reference/eda_re.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Re-expression function — eda_re","text":"function returns vector. used re-express data using one two  transformation techniques: Box-Cox transformation (tukey = FALSE) Tukey's power transformation (tukey = TRUE).","code":""},{"path":"/reference/eda_re.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Re-expression function — eda_re","text":"","code":"x <- c(15, 28, 17, 73,  8, 83,  2) eda_re(x, p=-1/3) #> [1] 0.4054801 0.3293169 0.3889111 0.2392723 0.5000000 0.2292489 0.7937005"},{"path":"/reference/eda_rline.html","id":null,"dir":"Reference","previous_headings":"","what":"Tukey's resistant line — eda_rline","title":"Tukey's resistant line — eda_rline","text":"eda_rline R implementation Hoaglin, Mosteller Tukey's  resistant line technique outlined chapter 5 \"Understanding Robust  Exploratory Data Analysis\" (Wiley, 1983).","code":""},{"path":"/reference/eda_rline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tukey's resistant line — eda_rline","text":"","code":"eda_rline(dat, x, y)"},{"path":"/reference/eda_rline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tukey's resistant line — eda_rline","text":"dat Data frame x Column assigned x axis y Column assigned y axis","code":""},{"path":"/reference/eda_rline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tukey's resistant line — eda_rline","text":"Outputs list parameters: : Intercept b: Slope res: Residuals sorted x-values x: Sorted x values y: y values following sorted x-values xmed: Median x values third ymed: Median y values third index: Index sorted x values defining upper boundaries                      thirds","code":""},{"path":"/reference/eda_rline.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Tukey's resistant line — eda_rline","text":"Bits pieces RLIN.F FORTRAN code Velleman et. al's book used helping implement R subroutines. See accompanying vignette Resistant Line detailed breakdown resistant line technique.","code":""},{"path":"/reference/eda_rline.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Tukey's resistant line — eda_rline","text":"Velleman, P. F., D. C. Hoaglin. 1981. Applications, Basics Computing Exploratory Data Analysis. Boston: Duxbury Press. D. C. Hoaglin, F. Mosteller, J. W. Tukey. 1983. Understanding Robust Exploratory Data Analysis. Wiley.","code":""},{"path":"/reference/eda_rline.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tukey's resistant line — eda_rline","text":"","code":"# This first example fits a resistant line to the neoplasms data  M <- eda_rline(neoplasms, Temp, Mortality) plot(Mortality~Temp, neoplasms, pch=20) abline(a=M$a, b=M$b, col=rgb(1,0,0,0.5))   # This second example uses breast cancer data from \"ABC's of EDA\" page 127. # The output model's  parameters should closely match:  Y = -46.19 + 2.89X # The plots shows the original data with a fitted resistant line (red) # and a regular lm fitted line (dashed grey), and the modeled residuals. # The 3-point summary dots are shown in red.  r.lm <- eda_rline(neoplasms, Temp, Mortality) r.lm #> $b #> [1] 2.890173 #>  #> $a #> [1] -45.90578 #>  #> $res #>  [1]  21.2982659   0.1398844  -2.1791908   8.8294798 -11.2485549  -7.6167630 #>  [7]  -0.1398844   4.7589595  -9.0092486  -2.1994220   2.7554913  -7.2676301 #> [13]  -0.3907514   6.1861272   1.7971098   0.1398844 #>  #> $x #>  [1] 31.8 34.0 40.2 42.1 42.3 43.5 44.2 45.1 46.3 47.3 47.8 48.5 49.2 49.9 50.0 #> [16] 51.3 #>  #> $y #>  [1]  67.3  52.5  68.1  84.6  65.1  72.2  81.7  89.2  78.9  88.6  95.0  87.0 #> [13]  95.9 104.5 100.4 102.5 #>  #> $xmed #> [1] 40.2 45.7 49.9 #>  #> $ymed #> [1]  67.30  85.15 100.40 #>  #> $index #> [1]  5 11 16 #>   # Check output OP <- par( mfrow = c(2,1))   plot(Mortality ~ Temp, neoplasms)   mtext(sprintf(\"y = %f + (%f)x\", r.lm$a, r.lm$b ))   abline(a = r.lm$a, b = r.lm$b, col=\"red\")   abline( lm(Mortality ~ Temp, neoplasms), col=\"grey\", lty=3)   points(cbind(r.lm$xmed,r.lm$ymed), pch =16, col=\"red\")   abline(v= r.lm$x[r.lm$index],lty=3)   plot(r.lm$res ~ r.lm$x)   abline( h = 0, lty=3)  par(OP)  # This next example compares children height to age. # The plots shows the original data with a fitted resistant line (red) # and a regular lm fitted line (dashed grey), and the modeled residuals. # The 3-point summary dots are shown in red. r.lm    <- eda_rline(age_height, Months, Height)  OP <- par( mfrow = c(2,1))  plot(Height ~ Months, age_height, xlab=\"Age (months)\", ylab=\"Height (cm)\")  mtext(sprintf(\"y = %f + (%f)x\", r.lm$a, r.lm$b ))  abline(a = r.lm$a, b = r.lm$b, col=\"red\")  abline( lm(Height ~ Months, age_height), col=\"grey\", lty=3)  points(cbind(r.lm$xmed,r.lm$ymed), pch =16, col=\"red\")  abline(v= r.lm$x[r.lm$index],lty=3)  plot(r.lm$res ~ r.lm$x)  abline( h = 0, lty=3)  par(OP)  # Andrew Siegel's pathological 9-point data set r.lm <- eda_rline(nine_point, X, Y)  OP <- par( mfrow = c(2,1)) plot(Y ~ X, nine_point, xlab=\"Age (months)\", ylab=\"Height (cm)\")    mtext(sprintf(\"y = %f + (%f)x\", r.lm$a, r.lm$b ))    abline(a = r.lm$a, b = r.lm$b, col=\"red\")    abline( lm(Y ~ X, nine_point), col=\"grey\", lty=3)    points(cbind(r.lm$xmed,r.lm$ymed), pch =16, col=\"red\")    abline(v= r.lm$x[r.lm$index],lty=3)    plot(r.lm$res ~ r.lm$x)    abline( h = 0, lty=3)  par(OP)"},{"path":"/reference/eda_sl.html","id":null,"dir":"Reference","previous_headings":"","what":"Tukey's spread-level function — eda_sl","title":"Tukey's spread-level function — eda_sl","text":"eda_sl function generates spread-level    table univariate dataset.","code":""},{"path":"/reference/eda_sl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tukey's spread-level function — eda_sl","text":"","code":"eda_sl(dat, x, y, sprd = \"frth\")"},{"path":"/reference/eda_sl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tukey's spread-level function — eda_sl","text":"dat Dataframe x Categorical variable column y Continuous variable column sprd Choice spreads. Either interquartile, sprd = \"IQR\" fourth-spread, sprd = \"frth\" (default).","code":""},{"path":"/reference/eda_sl.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Tukey's spread-level function — eda_sl","text":"Note function confused Bill Cleveland's   spread-location function. x categorical, output produce many NA's. page 59, Hoaglan et. al define fourth-spread range   defined upper fourth lower fourth. eda_lsum function used   compute upper/lower fourths.","code":""},{"path":"/reference/eda_sl.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Tukey's spread-level function — eda_sl","text":"Understanding Robust Exploratory Data Analysis, Hoaglin, David C., Frederick Mosteller, John W. Tukey, 1983.","code":""},{"path":"/reference/eda_sl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tukey's spread-level function — eda_sl","text":"","code":"sl <- eda_sl(iris, Species, Sepal.Length) plot(spread ~ level, sl, pch=16)"},{"path":"/reference/eda_trim.html","id":null,"dir":"Reference","previous_headings":"","what":"Trims vector and dataframe objects — eda_trim","title":"Trims vector and dataframe objects — eda_trim","text":"Removes records either tail-ends sorted dataset. Trimming can  performed number records (specify num = option)  quantiles (specify prop= option). eda_trim Trims vector eda_trim_df Trims data frame eda_ltrim Left-trims vector eda_rtrim Right-trims vector eda_ltrim_df Left-trims dataframe eda_rtrim_df Right-trims dataframe","code":""},{"path":"/reference/eda_trim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trims vector and dataframe objects — eda_trim","text":"","code":"eda_trim(x, prop = 0.05, num = 0)  eda_trim_df(dat, x, prop = 0.05, num = 0)  eda_ltrim(x, prop = 0.05, num = 0)  eda_ltrim_df(dat, x, prop = 0.05, num = 0)  eda_rtrim(x, prop = 0.05, num = 0)  eda_rtrim_df(dat, x, prop = 0.05, num = 0)"},{"path":"/reference/eda_trim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Trims vector and dataframe objects — eda_trim","text":"x Vector values (trimming vector) column whose values used trim dataframe (applies *_df functions ) prop Fraction values trim num Number values trim dat Dataframe (applies *_df functions )","code":""},{"path":"/reference/eda_trim.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Trims vector and dataframe objects — eda_trim","text":"input dataset need sorted (sorting performed  functions). num set zero, function assume  trimming done fraction (defined prop parameter). eda_trim eda_trim_df functions called,  num prop values apply tail. example,  num = 5 5 smallest 5 largest values removed  data. NA values must stripped input vector  column elements running trim functions. Elements returned sorted trimmed elements.","code":""},{"path":"/reference/eda_trim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Trims vector and dataframe objects — eda_trim","text":"","code":"# Trim a vector by 10% (i.e. 10% of the smallest and 10% of the largest # values) eda_trim( mtcars[,1], prop=0.1) #>  [1] 14.7 15.0 15.2 15.2 15.5 15.8 16.4 17.3 17.8 18.1 18.7 19.2 19.2 19.7 21.0 #> [16] 21.0 21.4 21.4 21.5 22.8 22.8 24.4 26.0 27.3  # Trim a data frame by 10% using the mpg column(i.e. 10% of the smallest # and 10% of the largest mpg values) eda_trim_df( mtcars, mpg, prop=0.1) #>                    mpg cyl  disp  hp drat    wt  qsec vs am gear carb #> Chrysler Imperial 14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4 #> Maserati Bora     15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8 #> Merc 450SLC       15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3 #> AMC Javelin       15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2 #> Dodge Challenger  15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2 #> Ford Pantera L    15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4 #> Merc 450SE        16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3 #> Merc 450SL        17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3 #> Merc 280C         17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4 #> Valiant           18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1 #> Hornet Sportabout 18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2 #> Merc 280          19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4 #> Pontiac Firebird  19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2 #> Ferrari Dino      19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6 #> Mazda RX4         21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4 #> Mazda RX4 Wag     21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4 #> Hornet 4 Drive    21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1 #> Volvo 142E        21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2 #> Toyota Corona     21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1 #> Datsun 710        22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1 #> Merc 230          22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2 #> Merc 240D         24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2 #> Porsche 914-2     26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2 #> Fiat X1-9         27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1"},{"path":"/reference/eda_unipow.html","id":null,"dir":"Reference","previous_headings":"","what":"Ladder of powers transformation on a single vector — eda_unipow","title":"Ladder of powers transformation on a single vector — eda_unipow","text":"eda_unipow re-expresses vector ladder powers plots  results using histogram density function. Either Tukey Box-Cox  transformation used computing re-expressed values.","code":""},{"path":"/reference/eda_unipow.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ladder of powers transformation on a single vector — eda_unipow","text":"","code":"eda_unipow(   x,   p = c(2, 1, 1/2, 0.33, 0, -0.33, -1/2, -1, -2),   tukey = TRUE,   bins = 5,   cex.main = 1.3,   col = \"#DDDDDD\",   border = \"#AAAAAA\",   title = \"Re-expressed data via ladder of powers\",   ... )"},{"path":"/reference/eda_unipow.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ladder of powers transformation on a single vector — eda_unipow","text":"x Vector p Vector powers tukey TRUE (default), apply Tukey's power transformation, FALSE adopt Box-Cox transformation bins Number histogram bins cex.main Histogram title size (assigned histogram plot) col Histogram fill color border Histogram border color title Overall plot title (set NULL title) ... parameters passed graphics::hist function.","code":""},{"path":"/reference/eda_unipow.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Ladder of powers transformation on a single vector — eda_unipow","text":"output lattice descriptive plots showing transformed data  across different powers.","code":""},{"path":"/reference/eda_unipow.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Ladder of powers transformation on a single vector — eda_unipow","text":"Tukey, John W. 1977. Exploratory Data Analysis. Addison-Wesley.","code":""},{"path":"/reference/eda_unipow.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ladder of powers transformation on a single vector — eda_unipow","text":"","code":"data(mtcars) eda_unipow(mtcars$mpg, bins=6)"},{"path":"/reference/neoplasms.html","id":null,"dir":"Reference","previous_headings":"","what":"Breast cancer mortality vs. temperature — neoplasms","title":"Breast cancer mortality vs. temperature — neoplasms","text":"data represent relationship mean annual temperature breast cancer mortality rate.","code":""},{"path":"/reference/neoplasms.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Breast cancer mortality vs. temperature — neoplasms","text":"","code":"neoplasms"},{"path":"/reference/neoplasms.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Breast cancer mortality vs. temperature — neoplasms","text":"data frame 16 rows 2 variables: Temp Temperature degrees Fahrenheit. Mortality Mortality rate presented index.","code":""},{"path":"/reference/neoplasms.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Breast cancer mortality vs. temperature — neoplasms","text":"Applications, Basics Computing Exploratory Data Analysis,       P.F. Velleman D.C. Hoaglin, 1981. (page 127)","code":""},{"path":"/reference/nine_point.html","id":null,"dir":"Reference","previous_headings":"","what":"Andrew Siegel's pathological 9-point dataset — nine_point","title":"Andrew Siegel's pathological 9-point dataset — nine_point","text":"synthetic dataset created test robustness fitted lines. Originally published Andrew Siegel later adapted Hoaglin et al.'s book.","code":""},{"path":"/reference/nine_point.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Andrew Siegel's pathological 9-point dataset — nine_point","text":"","code":"nine_point"},{"path":"/reference/nine_point.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Andrew Siegel's pathological 9-point dataset — nine_point","text":"data frame 9 rows 2 variables: X X values Y Y values","code":""},{"path":"/reference/nine_point.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Andrew Siegel's pathological 9-point dataset — nine_point","text":"Robust regression using repeated medians, Andrew F. Siegel, Biometrika,    vol 69, n 1, 1982. Understanding robust exploratory data analysis, D.C. Hoaglin,    F. Mosteller J.W. Tukey. 1983 (page 139)","code":""},{"path":"/reference/plot.eda_polish.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot eda_polish tables or diagnostic plots — plot.eda_polish","title":"Plot eda_polish tables or diagnostic plots — plot.eda_polish","text":"eda_pol plot method lists eda_polish class.","code":""},{"path":"/reference/plot.eda_polish.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot eda_polish tables or diagnostic plots — plot.eda_polish","text":"","code":"# S3 method for eda_polish plot(   x,   type = \"residuals\",   k = 1,   col.quant = FALSE,   colpal = \"RdYlBu\",   col.eff = TRUE,   col.com = TRUE,   adj.mar = FALSE,   res.size = 1,   row.size = 1,   col.size = 1,   res.txt = TRUE,   label.txt = TRUE,   ... )"},{"path":"/reference/plot.eda_polish.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot eda_polish tables or diagnostic plots — plot.eda_polish","text":"x list class eda_polish type Plot type. One three: \"residuals\", \"cv\" \"diagnostic\". k cv values plotted, define k parameter col.quant Boolean indicating quantile classification scheme used colpal Color palette adopt col.eff Boolean indicating effects common value contribute color gradient col.com Boolean indicating common value contribute color gradient adj.mar Boolean indicating margin width needs accommodate labels res.size Size residual values plot [0-1] row.size Size row effect values plot [0-1] col.size Size column effect values plot [0-1] res.txt Boolean indicating values added plot label.txt Boolean indicating margin column labels plotted ... Arguments passed subsequent methods","code":""},{"path":"/reference/plot.eda_polish.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot eda_polish tables or diagnostic plots — plot.eda_polish","text":"function plots polish table residuals CV values. also generate  diagnostic plot type set diagnostic","code":""},{"path":"/reference/plot.eda_polish.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot eda_polish tables or diagnostic plots — plot.eda_polish","text":"","code":"# Create dataset df <- data.frame(region =  rep( c(\"NE\", \"NC\", \"S\", \"W\"), each = 5), edu = rep( c(\"ed8\", \"ed9to11\", \"ed12\", \"ed13to15\", \"ed16\"), 4), perc = c(25.3, 25.3, 18.2, 18.3, 16.3, 32.1, 29, 18.8,         24.3, 19, 38.8, 31, 19.3, 15.7, 16.8, 25.4, 21.1, 20.3, 24, 17.5))  # Generate median polish output out <- eda_pol(df, row = \"region\", col = \"edu\", val = \"perc\", plot = FALSE)  # Plot table plot(out, type = \"residuals\")    # Plot table using CV values plot(out, type = \"cv\")   # Generate diagnostic plot plot(out, type = \"diagnostic\")  #> $slope #>     cv  #> 1.3688  #>"},{"path":"/reference/tukeyedar.html","id":null,"dir":"Reference","previous_headings":"","what":"Tukey inspired exploratory data analysis functions — tukeyedar","title":"Tukey inspired exploratory data analysis functions — tukeyedar","text":"packages hosts small set Tukey inspired functions use exploring datasets robust manner.","code":""},{"path":"/news/index.html","id":"tukeyedar-010","dir":"Changelog","previous_headings":"","what":"tukeyedar 0.1.0","title":"tukeyedar 0.1.0","text":"Initial release tukeyedar","code":""}]
