[{"path":"/articles/polish.html","id":"the-median-polish-basics","dir":"Articles","previous_headings":"","what":"The median polish basics","title":"Median polish","text":"median polish exploratory technique used extract effects two-way table. , median polish can thought robust version two-way ANOVA–goal characterize role factor contributing towards expected value. iteratively extracting effects associated row column factors via medians. example, given two-way table 1964 1966 infant mortality rates1 (reported count per 1000 live births) computed combination geographic region (NE, NC, S, W) level father’s educational attainment (ed8, ed9-11, ed12, ed13-15, ed16), median polish first extract overall median value, smooth residual rates first extracting median values along column (thus contributing column factor), smooth remaining residual rates extracting median values along row (thus contributing row factor). smoothing operation iterated residuals stabilize. workflow highlighted following figure.  left-table original data showing death rates. second table shows outcome first round polishing (including initial overall median value 20.2). third forth table show second third iterations smoothing operations. Additional iterations deemed necessary given little can extracted residuals. detailed step--step explanation workflow see . resulting model additive form : \\[ y_{ij} = \\mu + \\alpha_{} + \\beta_{j} +\\epsilon_{ij} \\] \\(y_{ij}\\) response variable row \\(\\) column \\(j\\), \\(\\mu\\) overall typical value (hereafter referred common value), \\(\\alpha_{}\\) row effect, \\(\\beta_{j}\\) column effect \\(\\epsilon_{ij}\\) residual value left effects taken account. factor’s levels displayed top row left-column. example, region assigned rows father’s educational attainment assigned columns. father’s educational attainment can explain 11 units variability (7.58 - (-3.45)) death rates vs 4 units variability region (2.55 - (-1.5)). , father’s educational attainment larger contributor expected infant mortality regional effect.","code":""},{"path":"/articles/polish.html","id":"implementing-the-median-polish","dir":"Articles","previous_headings":"","what":"Implementing the median polish","title":"Median polish","text":"package’s eda_polish augmented version built-medpolish available via stats package. key difference eda_polish takes input dataset long form opposed medpolish takes dataset form matrix. example, infant mortality dataset needs consist least three columns: one variable (two factors expected value). median polish can executed follows:  function output table plot along list components stored M1 object. want suppress plot, can set parameter plot = FALSE. M1 object class eda_polish. can extract common values, row column effects follows:","code":"grd <- c(\"ed8\", \"ed9-11\", \"ed12\", \"ed13-15\", \"ed16\") dat <- data.frame(region =  rep( c(\"NE\", \"NC\", \"S\", \"W\"), each = 5),                   edu = factor(rep( grd , 4), levels = grd),                   perc = c(25.3, 25.3, 18.2, 18.3, 16.3, 32.1, 29, 18.8,                            24.3, 19, 38.8, 31, 19.3, 15.7, 16.8, 25.4,                             21.1, 20.3, 24, 17.5)) head(dat)     region     edu perc   1     NE     ed8 25.3   2     NE  ed9-11 25.3   3     NE    ed12 18.2   4     NE ed13-15 18.3   5     NE    ed16 16.3   6     NC     ed8 32.1 library(tukeyedar) M1 <- eda_pol(dat, row = region, col = edu, val = \"perc\") M1$global   [1] 20.85 M1$row     region  effect   1     NC  2.3000   2     NE -1.4625   3      S -0.3500   4      W  0.3500 M1$col         edu   effect   1     ed8  7.43125   2  ed9-11  5.88125   3    ed12 -1.19375   4 ed13-15  0.03125   5    ed16 -3.70000"},{"path":"/articles/polish.html","id":"ordering-rows-and-columns-by-effect-values","dir":"Articles","previous_headings":"Implementing the median polish","what":"Ordering rows and columns by effect values","title":"Median polish","text":"order row column effects effect values, set sort parameter TRUE.","code":"M1 <- eda_pol(dat, row = region, col = edu, val = perc, sort = TRUE)"},{"path":"/articles/polish.html","id":"applying-a-transformation-to-the-data","dir":"Articles","previous_headings":"Implementing the median polish","what":"Applying a transformation to the data","title":"Median polish","text":"can function re-express values prior performing polish. example, log transform data, pass value 0 p.  re-expressing data using negative power, choice adopting Tukey transformation (tukey = TRUE) Box-Cox transformation (tukey = FALSE). example, apply power transformation -0.1 using Box-Cox transformation, type:","code":"M1 <- eda_pol(dat, row = region, col = edu, val = perc, p = 0) M1 <- eda_pol(dat, row = region, col = edu, val = perc, p = -0.1, tukey = FALSE)"},{"path":"/articles/polish.html","id":"defining-the-statistic","dir":"Articles","previous_headings":"Implementing the median polish","what":"Defining the statistic","title":"Median polish","text":"default, polishing routine adopts median statistic. can adopt statistic via stat parameter. example, apply mean polish, type:","code":"M1 <- eda_pol(dat, row = region, col = edu, val = perc, stat = mean)"},{"path":"/articles/polish.html","id":"the-eda_polish-plot-method","dir":"Articles","previous_headings":"","what":"The eda_polish plot method","title":"Median polish","text":"list object created eda_pol function class eda_polish. , plot method created class. plot method either output original polished table (type = \"residuals\"), diagnostic plot (type = \"diagnostic\"), CV values (cv).","code":""},{"path":"/articles/polish.html","id":"plot-the-median-polish-table","dir":"Articles","previous_headings":"","what":"Plot the median polish table","title":"Median polish","text":"can generate plot table median polish model follows:","code":"M1 <- eda_pol(dat, row = region, col = edu, val = perc, plot = FALSE) plot(M1)"},{"path":[]},{"path":"/articles/polish.html","id":"excluding-common-effect-from-the-color-palette-range","dir":"Articles","previous_headings":"Adjusting color schemes","what":"Excluding common effect from the color palette range","title":"Median polish","text":"default, range color palettes defined range values table. includes common value. prevent common value affecting distribution color palettes, set col.com FALSE.  Note distribution colors maximized help improve view effects. view makes clear father’s educational attainment greater effect region.","code":"plot(M1, col.com = FALSE)"},{"path":"/articles/polish.html","id":"excluding-rowcolumn-effects-from-the-color-palette-range","dir":"Articles","previous_headings":"Adjusting color schemes","what":"Excluding row/column effects from the color palette range","title":"Median polish","text":"want plot focus residuals maximizing range colors fit range residual values, set col.eff = FALSE.  Note setting col.eff FALSE prevent effects cells colored. simply ensures range colors maximized match full range residual values. effect value falls within residual range assigned color.","code":"plot(M1, col.eff = FALSE)"},{"path":"/articles/polish.html","id":"changing-color-schemes","dir":"Articles","previous_headings":"Adjusting color schemes","what":"changing color schemes","title":"Median polish","text":"default, color scheme symmetrical centered 0. adopts R’s (version 4.1 ) built-\"RdYlBu\" color palettes. can assign different built-color palettes via colpal parameter. can list available colors R via hcl.pals() function. want limit output divergent color palettes, type: example, can assign \"Green-Brown\" color palette follows. (’ll remove common value range input values maximize displayed set colors).  default classification scheme symmetrical linear, centered 0. want maximize use colors, regardless range values, can set col.quant TRUE.  ’ll note regardless asymmetrical distribution values 0, cell assigned unique color swatch. adopting quantitative color classification scheme, might want adopt color palette generates fewer unique hues variation lightness values. example,","code":"hcl.pals(type = \"diverging\")    [1] \"Blue-Red\"      \"Blue-Red 2\"    \"Blue-Red 3\"    \"Red-Green\"        [5] \"Purple-Green\"  \"Purple-Brown\"  \"Green-Brown\"   \"Blue-Yellow 2\"    [9] \"Blue-Yellow 3\" \"Green-Orange\"  \"Cyan-Magenta\"  \"Tropic\"          [13] \"Broc\"          \"Cork\"          \"Vik\"           \"Berlin\"          [17] \"Lisbon\"        \"Tofino\" plot(M1, colpal = \"Green-Brown\", col.com = FALSE) plot(M1, col.quant = TRUE) plot(M1, col.quant = TRUE, colpal = \"Green-Orange\")"},{"path":"/articles/polish.html","id":"adjusting-text","dir":"Articles","previous_headings":"","what":"Adjusting text","title":"Median polish","text":"can omit labeled values output setting res.txt FALSE.  Likewise can omit axes labels setting label.txt FALSE. may prove useful applying median polish large grid file.  can adjust text size via res.size, row.size col.size parameters numeric values, row names, column names respectively. example, set sizes 60% default value type:","code":"plot(M1, res.txt = FALSE) plot(M1, res.txt = FALSE, label.txt = FALSE) plot(M1, row.size = 0.6, col.size = 0.6 , res.size = 0.6)"},{"path":"/articles/polish.html","id":"exploring-diagnostic-plots","dir":"Articles","previous_headings":"","what":"Exploring diagnostic plots","title":"Median polish","text":"plot method also generate plot residuals vs comparison values (CV) herein referred diagnostic plot.  plot shows relationship CV values residuals. bisquare robust line fitted data (light red line) along robust loess fit (dashed blue line). function also output line’s slope. slope can used help estimate transformation data, needed. generate plot, simply extract cv component M1 list. cv component dataframe stores residuals (first column) CV values (fourth column). first records data frame shown next. diagnostic plot helps identify interactions effects. interaction suspected, model longer simple additive model; model needs augmented interactive component form: \\[ y_{ij} = \\mu + \\alpha_{} + \\beta_{j} + kCV +\\epsilon_{ij} \\] \\(CV\\) = \\(\\alpha_{}\\beta_{j}/\\mu\\) \\(k\\) constant can estimated slope generated diagnostic plot. truly additive model one changes response variable one level another level remain constant. example, given bottom-left matrix initial response values, changes response variable level level b constant regardless row effect. example, going b level z elicits change response 6 - 3 = 3. observed change values b levels x y (4-1 5-2 respectively). three row levels, change expected values b –increase 3 units. Likewise, changes response values rows x y y z constant (1) across levels column effect. additive effect can observed interaction plot shown right. column effect plotted along x-axis, row effect mapped line segment. Original dataset (left). Interaction plot (right). Parallel lines indicate interaction effects. median polish generates following table diagnostic plot: Median polished data showing interaction effects ’ll note lack pattern (flat one) accompanying diagnostic plot. Now, let’s see happens interaction fact present two way table. Original dataset (left). Interaction plot (right). Note lines longer parallel one another interaction plot. Now let’s run median polish generate diagnostic plot. Median polished data showing interaction effects ’ll note upward trend residuals increasing comparison values. usually good indication interaction effects. Another tell-tell sign pattern observed residuals low residuals high residuals opposing corners table. interaction observed, either include interaction term additive model, seek re-expression might help alleviate interaction effects. choose include interaction term model, coefficient \\(k\\) can extracted slope generated diagnostic plot. choose re-express data hopes removing interaction data, can try using power transformation equal \\(1 - slope\\) (slope derived diagnostic plot). infant mortality dataset suggest interaction effects diagnostic plot. Next, ’ll look another dataset may exhibit interaction effects.","code":"plot(M1, type = \"diagnostic\") $slope       cv    1.3688 head(M1$cv)         perc region.eff  edu.eff            cv   1 -3.15625     2.3000 -1.19375 -0.1316846523   2 -0.00625    -0.3500 -1.19375  0.0200389688   3  0.00625    -1.4625 -1.19375  0.0837342626   4  0.29375     0.3500 -1.19375 -0.0200389688   5 -4.83125    -0.3500  0.03125 -0.0005245803   6  1.11875     2.3000  0.03125  0.0034472422"},{"path":"/articles/polish.html","id":"another-example-earnings-by-sex-for-2021","dir":"Articles","previous_headings":"Exploring diagnostic plots","what":"Another example: Earnings by sex for 2021","title":"Median polish","text":"dataset consists earnings sex levels educational attainment 2021 (src: US Census Bureau). Education levels defined follows: + NoHS: Less High School Graduate + HS: High School Graduate (Includes Equivalency) + AD: College Associate’s Degree + Grad: Bachelor’s Degree original table (prior running median polish), can viewed setting maxiter 0 call eda_pol. 2021 Average earnings US. Next, ’ll run median polish. Next, plot final table diagnostic plot.  ’s can glean output: Overall, median earnings $41,359 Variability earnings due different levels education attainment covers range $56,936 different sexes covers range $15,858. residuals quite large suggesting may much variability earnings may explained row column effects. residuals explain $15,780 variability data. diagnostic plot suggests strong interaction sex effect education effect. implies, example, differences earnings sexes depend level educational attainment. slope residuals CV values around 0.94. Given strong evidence interaction effects, need take one two actions: can either add comparison values (CV) row-plus-column model, can see re-expressing earnings values eliminates dependence effects.","code":"edu <- c(\"NoHS\", \"HS\", \"HS+2\", \"HS+4\", \"HS+6\") df1 <- data.frame(Education = factor(rep(edu,2), levels = edu),                   Sex = c(rep(\"Male\", 5), rep(\"Female\",5)),                   Earnings = c(31722, 40514, 49288, 73128,98840,20448,                                     26967, 33430, 50554, 67202)) eda_pol(df1, row = Education, col = Sex, val = Earnings , maxiter = 0, adj.mar = TRUE) M2 <- eda_pol(df1, row = Education, col = Sex, val = Earnings , plot = FALSE) plot(M2, adj.mar = TRUE, res.size = 0.8, row.size = 0.8, col.size = 0.8)  plot(M2, \"diagnostic\") $slope          cv    0.9410244"},{"path":"/articles/polish.html","id":"adding-cv-to-the-row-plus-column-model","dir":"Articles","previous_headings":"Exploring diagnostic plots > Another example: Earnings by sex for 2021","what":"Adding CV to the row-plus-column model","title":"Median polish","text":"CV values computed stored median polish object. can extracted model via M2$cv component can visualized via plot function. following figure shows original residuals table (left) CV table (right). Median polish residuals (left) CV values (right). comparsion value added model, need compute new set residuals. residuals can plotted setting add.cv TRUE specifying value k. Using slope estimate k get: CV values (left) new set residuals (right). two tables provide us parameters needed construct model. example, Female-NoHS earnings value can recreated table follows: \\[ Earnings_{Female-NoHS} = \\mu + Sex_{Female} + Education_{NoHS} + kCV_{Female-NoHS} + \\epsilon_{Female-NoHS} \\] : \\(CV_{Female-NoHS} = \\frac{(Sex_{Female})(Education_{NoHS})}{\\mu}\\) \\(k\\) constant can estimated diagnostic plot’s slope (0.94 example). gives us: \\[ Earnings_{Female-NoHS} = 41359 -7929 -15274 + (0.94)(2928.2) -460.5 \\]","code":"plot(M2, adj.mar = TRUE, res.size = 0.8, row.size = 0.8, col.size = 0.8)  plot(M2, \"cv\", adj.mar = TRUE, res.size = 0.8, row.size = 0.8, col.size = 0.8) plot(M2, \"cv\", adj.mar = TRUE, res.size = 0.8, row.size = 0.8, col.size = 0.8) plot(M2, \"residuals\", add.cv=TRUE, k = 0.94,      adj.mar = TRUE, res.size = 0.8, row.size = 0.8, col.size = 0.8)"},{"path":"/articles/polish.html","id":"re-expressing-earnings","dir":"Articles","previous_headings":"Exploring diagnostic plots > Another example: Earnings by sex for 2021","what":"Re-expressing earnings","title":"Median polish","text":"’s possible earnings presented us scale best suited analysis. Subtracting slope value (derived diagnostic plot) value 1 offers suggested transformation may provide us scale measure best suited data. ’ll rerun median polish using power transformation 1 - 0.94 = 0.06. Next, plot final table diagnostic plot. Median polish output (left) CV values (right). power 0.06 may bit aggressive given ’ve gone positive relationship CV residual negative relationship two. Tweaking power parameter may recommended. can done via trial error, can done using technique described next.","code":"M3 <- eda_pol(df1, row = Education, col = Sex, val = Earnings ,                plot = FALSE, p = 0.06) plot(M3, adj.mar = TRUE, res.size = 0.8, row.size = 0.8, col.size = 0.8)  plot(M3, \"diagnostic\")"},{"path":"/articles/polish.html","id":"fine-tuning-a-re-expression","dir":"Articles","previous_headings":"Exploring diagnostic plots > Another example: Earnings by sex for 2021","what":"Fine tuning a re-expression","title":"Median polish","text":"Klawonn et al.2 propose method honing optimal power transformation finding one maximizes effect’s spreads vis--vis residuals. computing ratio interquartile range row column effects 80% quantile residual’s absolute values. following code chunk computes ratio different power transformations. Row (left) column (right) effect IQRs residuals ratio vs power. plot suggests power transformation 0.1. ’ll re-run median polish using power transformation.  slope much smaller loess fit suggests monotonically increasing decreasing relationship residuals CV values. Re-expressing value seems done good job stabilizing residuals across CV values. ’ll modify color scheme place emphasis effects opposed overall value.  ’s can glean output: earnings values best presented power 0.1 scale. Overall, median earnings (re-expressed form) $19. Variability earnings due different levels education attainment covers range $3 different sexes covers range $1. residuals much smaller relative effects earnings re-expressed. residuals explain close $0 variability data. Just variability can expalined effects. Re-expressing values eliminates interaction effects.","code":"f1 <- function(x){   out <- eda_pol(df1, row = Education, col = Sex, val = Earnings,                  p = x, plot=FALSE, tukey = FALSE)   c(p=out$power, IQrow = out$IQ_row, IQcol = out$IQ_col) }  IQ <- t(sapply(0:25/10,  FUN = f1 )) # Apply transformations at 0.1 intervals  plot(IQrow ~ p, IQ, type=\"b\") grid() plot(IQcol ~ p, IQ, type=\"b\") grid() M4 <- eda_pol(df1, row = Education, col = Sex, val = Earnings,                plot = FALSE, p = 0.1) plot(M4, adj.mar = TRUE, res.size = 0.8, row.size = 0.8, col.size = 0.8)  plot(M4, \"diagnostic\") plot(M4, adj.mar = TRUE, col.com = FALSE,       res.size = 0.8, row.size = 0.8, col.size = 0.8)"},{"path":"/articles/polish.html","id":"the-mean-polish","dir":"Articles","previous_headings":"","what":"The mean polish","title":"Median polish","text":"eda_pol function accepts statistical summary function. default, uses median. example, mean polish generated earnings dataset looks like :  Polishing data using mean requires single iteration reach stable output. mean suffers sensitivity non-symmetrical distributions outliers. , median polish robust summary statistic. said, running mean polish benefits: ’s great way represent effects generated two-way analysis variance (aka 2-way ANOVA). confirmed comparing row column effects traditional 2-way ANOVA technique shown : median polish, must concern interactions effects. interaction present, ANOVA inferential statistics using F-test can untrustworthy.  strong evidence interaction. slope 0.92 can used estimate power transformation via \\(1 - slope\\). close power transformation 0.1 ended adopting median polish exercise. Results mean polish (left) diagnositc plot (right). Re-expressing data nice job removing interaction effects much like performed median polish. suggests one run two-way ANOVA, re-expression strongly suggested.","code":"M5 <- eda_pol(df1, row = Education, col = Sex, val = Earnings ,                stat = mean, plot = FALSE) plot(M5, adj.mar = TRUE, res.size = 0.8, row.size = 0.8, col.size = 0.8) model.tables(aov(Earnings ~ Sex + Education, df1))   Tables of effects       Sex    Sex   Female   Male     -9489   9489        Education    Education     NoHS     HS   HS+2   HS+4   HS+6    -23124 -15469  -7850  12632  33812 plot(M5, type = \"diagnostic\", adj.mar = TRUE, res.size = 0.8, row.size = 0.8, col.size = 0.8) $slope          cv    0.9223166 M4b <- eda_pol(df1, row = Education, col = Sex, val = Earnings , stat = mean,                plot = FALSE, p = 0.1, maxiter = 1) plot(M4b, adj.mar = TRUE, res.size = 0.8, row.size = 0.8, col.size = 0.8)  plot(M4b, \"diagnostic\")"},{"path":"/articles/RLine.html","id":"the-resistant-line-basics","dir":"Articles","previous_headings":"","what":"The resistant line basics","title":"Resistant Line","text":"eda_rline function fits robust line bivariate dataset. first breaking data three roughly equal sized batches following x-axis variable. uses batches’ median values compute slope intercept. However, function doesn’t stop . fitting inital line, function fits another line (following aforementioned methodology) model’s residuals. slope close zero, residual slope added original fitted model creating updated model. iteration repeated residual slope close zero residual slope changes sign (point average last two iterated slopes used final fit). example iteration follows using data Velleman et. al’s book. dataset, neoplasms, consists breast cancer mortality rates regions varying mean annual temperatures.  three batches divided follows:  Note 16 record dataset divisible three thus forcing extra point middle batch (remainder division three two, extra point added tail-end batches). Next, compute medians batch (highlighted red points following figure).  two end medians used compute slope : \\[ b = \\frac{y_r - y_l}{x_r-x_l} \\] subscripts \\(r\\) \\(l\\) reference median values right-left-batches. slope computed, intercept can computed follows: \\[ median(y_{l,m,r} - b * x_{l,m,r}) \\] \\((x,y)_{l,m,r}\\) median x y values batch. line used compute first set residuals. line fitted residuals following procedure outlined .  initial model slope intercept 3.412 -69.877 respectively residual’s slope intercept -0.873 41.451 respectively. residual slope added first computed slope process repeated thus generating following tweaked slope updated residuals:  updated slope now 3.412 + (-0.873) = 2.539. iteration continues slope residuals stabilize. final line working example ,  final slope intercept 2.89 -45.91, respectively.","code":""},{"path":"/articles/RLine.html","id":"implementing-the-resistant-line","dir":"Articles","previous_headings":"","what":"Implementing the resistant line","title":"Resistant Line","text":"eda_rline takes just three arguments: data frame, x variable y variable. function output list. elements b model’s intercept slope. vectors x y input values sorted x. res vector final residuals sorted x. xmed ymed vectors medians three batches. px py power transformations applied variables. output list class eda_rline. plot method available class.  see resistant line compares ordinary least-squares (OLS) regression slope, add output lm model plot via abline():  regression model computes slope 2.36 whereas resistant line function generates slope 2.89. scatter plot, can spot point may undo influence regression line (point highlighted green following plot).  Removing point data generates OLS regression line inline resistant model. point interest 15th record neoplasms data frame.  Note OLS slope inline generated resistant line. ’ll also note resistant line slope also changed. Despite resistant nature line, removal point changed makeup first tier values (note leftward shift vertical dashed line). changed makeup batch thus changing median values first second tier batches.","code":"library(tukeyedar) M <- eda_rline(neoplasms, Temp, Mortality) M #>  $b #>  [1] 2.890173 #>   #>  $a #>  [1] -45.90578 #>   #>  $res #>   [1]  21.2982659   0.1398844  -2.1791908   8.8294798 -11.2485549  -7.6167630 #>   [7]  -0.1398844   4.7589595  -9.0092486  -2.1994220   2.7554913  -7.2676301 #>  [13]  -0.3907514   6.1861272   1.7971098   0.1398844 #>   #>  $x #>   [1] 31.8 34.0 40.2 42.1 42.3 43.5 44.2 45.1 46.3 47.3 47.8 48.5 49.2 49.9 50.0 #>  [16] 51.3 #>   #>  $y #>   [1]  67.3  52.5  68.1  84.6  65.1  72.2  81.7  89.2  78.9  88.6  95.0  87.0 #>  [13]  95.9 104.5 100.4 102.5 #>   #>  $xmed #>  [1] 40.2 45.7 49.9 #>   #>  $ymed #>  [1]  67.30  85.15 100.40 #>   #>  $index #>  [1]  5 11 16 #>   #>  $xlab #>  [1] \"Temp\" #>   #>  $ylab #>  [1] \"Mortality\" #>   #>  $px #>  [1] 1 #>   #>  $py #>  [1] 1 #>   #>  $iter #>  [1] 4 #>   #>  attr(,\"class\") #>  [1] \"eda_rline\" plot(M) abline(lm(Mortality ~ Temp, neoplasms), lty = 2) points(neoplasms[15,], col=\"#43CD80\",cex=1.5 ,pch=20) neoplasms.sub <- neoplasms[-15,] M.sub <- eda_rline(neoplasms.sub, Temp, Mortality) plot(M.sub) abline(lm(Mortality ~ Temp, neoplasms.sub), lty = 2) # Regression model with data subset"},{"path":[]},{"path":"/articles/RLine.html","id":"nine-point-data","dir":"Articles","previous_headings":"Other examples","what":"Nine point data","title":"Resistant Line","text":"nine_point dataset used Hoaglin et. al (p. 139) test resistant line function’s ability stabilize wild oscillations computed slopes across iterations.  , slope intercept 0.067 0.133 respectively matching 1/15 2/15 values computed Hoaglin et. al.","code":"M <- eda_rline(nine_point, X,Y) plot(M)"},{"path":"/articles/RLine.html","id":"age-vs--height-data","dir":"Articles","previous_headings":"Other examples","what":"Age vs. height data","title":"Resistant Line","text":"age_height another dataset found Hoaglin et. al (p. 135). gives ages heights children private urban school.  , slope intercept 0.429 91.007 respectively matching 0.426 slope closely matching 90.366 intercept values computed Hoaglin et. al page 137.","code":"M <- eda_rline(age_height, Months,Height) plot(M)"},{"path":"/articles/RLine.html","id":"not-all-relationships-are-linear","dir":"Articles","previous_headings":"","what":"Not all relationships are linear!","title":"Resistant Line","text":"’s important remember resistant line technique valid bivariate relationship linear. , ’ll step example highlighted Velleman et. al (p. 138) using R built-mtcars dataset. First, ’ll fit resistant line data.  ’s important note just resistant line can fit necessarily imply relationship linear. assess linearity mtcars dataset, ’ll make use eda_3pt function (see accompanying vignette details interpreting 3-point summary function).  ’s clear two half slopes relationship linear. Velleman et. al first suggest re-expressing mpg 1/mpg (.e. applying power transformation -1) giving us number gallons consumed per mile driven.  two half slopes still differ. therefore opt re-express disp variable. One possibility take inverse 1/3 since displacement measure volume (e.g. length3) gives us:  Now identified re-expressions linearises relationship, can fit resistant line. (Note grey line generated eda_3pt function resistant line generated eda_rline.)","code":"M <- eda_rline(mtcars, disp, mpg) plot(M) eda_3pt(mtcars, disp, mpg) eda_3pt(mtcars, disp, mpg, py = -1, ylab = \"gal/mi\") eda_3pt(mtcars, disp, mpg,  px = -1/3, py = -1,         ylab = \"gal/mi\", xlab = expression(\"Displacement\"^{-1/3})) M <- eda_rline(mtcars, disp, mpg,  px = -1/3, py = -1) plot(M, ylab = \"gal/mi\", xlab = expression(\"Displacement\"^{-1/3}))"},{"path":"/articles/RLine.html","id":"computing-a-confidence-interval","dir":"Articles","previous_headings":"","what":"Computing a confidence interval","title":"Resistant Line","text":"Confidence intervals coefficients can estimated using bootstrapping techniques. two approaches: resampling residuals resampling x-y cases.","code":""},{"path":"/articles/RLine.html","id":"resampling-the-model-residuals","dir":"Articles","previous_headings":"Computing a confidence interval","what":"Resampling the model residuals","title":"Resistant Line","text":", fit resistant line extract residuals. re-run model many times replacing original y values modeled y values plus resampled residuals generate confidence intervals. Now plot distributions,  tabulate 95% confidence interval.","code":"n  <- 599 # Set number of iterations M  <- eda_rline(neoplasms, Temp, Mortality) # Fit the resistant line bt <- array(0, dim=c(n, 2)) # Create empty bootstrap array for(i in 1:n){ #bootstrap loop   df.bt <- data.frame(x=M$x, y = M$y +sample(M$res,replace=TRUE))   bt[i,1] <- eda_rline(df.bt,x,y)$a   bt[i,2] <- eda_rline(df.bt,x,y)$b } hist(bt[,1], main=\"Intercept distribution\") hist(bt[,2], main=\"Slope distribution\") conf <- t(data.frame(Intercept = quantile(bt[,1], p=c(0.05,0.95) ),                      Slope = quantile(bt[,2], p=c(0.05,0.95) ))) conf #>                    5%       95% #>  Intercept -75.399410 10.605693 #>  Slope       1.643889  3.515459"},{"path":"/articles/RLine.html","id":"resampling-the-x-y-paired-values","dir":"Articles","previous_headings":"Computing a confidence interval","what":"Resampling the x-y paired values","title":"Resistant Line","text":", resample x-y paired values (replacement) compute resistant line time. Now plot distributions,  tabulate 95% confidence interval.","code":"n  <- 599 # Set number of iterations bt <- array(0, dim=c(n, 2)) # Create empty bootstrap array for(i in 1:n){ #bootstrap loop   recs <- sample(1:nrow(neoplasms), replace = TRUE)   df.bt <- neoplasms[recs,]   bt[i,1]=eda_rline(df.bt,Temp,Mortality)$a   bt[i,2]=eda_rline(df.bt,Temp,Mortality)$b } hist(bt[,1], main=\"Intercept distribution\") hist(bt[,2], main=\"Slope distribution\") conf <- t(data.frame(Intercept = quantile(bt[,1], p=c(0.05,0.95) ),                      Slope = quantile(bt[,2], p=c(0.05,0.95) ))) conf #>                     5%       95% #>  Intercept -112.594795 15.031034 #>  Slope        1.643678  4.254098"},{"path":"/articles/RLine.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Resistant Line","text":"Applications, Basics Computing Exploratory Data Analysis, P.F. Velleman D.C. Hoaglin, 1981. Understanding robust exploratory data analysis, D.C. Hoaglin, F. Mosteller J.W. Tukey, 1983.","code":""},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Manuel Gimond. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"text","code":"@Misc{,   title = {tukeyedar: A package of Tukey inspired EDA functions},   author = {Manuel Gimond},   url = {https://mgimond.github.io/tukeyedar/},   year = {2021}, }"},{"path":"/index.html","id":"tukeyedar","dir":"","previous_headings":"","what":"Tukey Inspired Exploratory Data Analysis Functions","title":"Tukey Inspired Exploratory Data Analysis Functions","text":"tukeyedar package houses subset functions used Exploratory Data Analysis (EDA). functions inspired work published Tukey (1977), D. C. Hoaglin Tukey (1983) Velleman Hoaglin (1981). Note package beta mode, use discretion. Many plots generated functions necessarily geared publication designed focus viewer’s attention patterns generated plots (hence reason light colored axes missing axes labels plots ).","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Tukey Inspired Exploratory Data Analysis Functions","text":"can install development version tukeyedar GitHub : Note vignettes automatically generated command; note vignettes available website (see next section). want local version vignettes, add build_vignettes = TRUE parameter. vignette require dplyr installed since eda_sl function relies . dplyr already installed, aforementioned syntax automatically install . reason vignettes created, might want re-install package force=TRUE parameter.","code":"# install.packages(\"devtools\") devtools::install_github(\"mgimond/tukeyedar\") devtools::install_github(\"mgimond/tukeyedar\", build_vignettes = TRUE) devtools::install_github(\"mgimond/tukeyedar\", build_vignettes = TRUE, force=TRUE)"},{"path":"/index.html","id":"vignettes","dir":"","previous_headings":"","what":"Vignettes","title":"Tukey Inspired Exploratory Data Analysis Functions","text":"’s strongly recommended read vignettes. can accessed website: detailed rundown resistant line function median polish chose vignettes locally created installed package, can view locally via vignette(\"RLine\", package = \"tukeyedar\"). use dark themed IDE, vignettes may render well might opt view web browser via functions RShowDoc(\"RLine\", package = \"tukeyedar\").","code":""},{"path":"/index.html","id":"using-the-functions","dir":"","previous_headings":"","what":"Using the functions","title":"Tukey Inspired Exploratory Data Analysis Functions","text":"functions start eda_. example, generate three point summary plot mpg vs. disp mtcars dataset, type:  Note functions pipe friendly. example, following wrokd:","code":"library(tukeyedar) eda_3pt(mtcars, disp, mpg) #> $slope1 #> [1] -0.1117241 #>  #> $slope2 #> [1] -0.0220894 #>  #> $hsrtio #> [1] 0.1977137 #>  #> $xmed #> [1]  95.1 167.6 360.0 #>  #> $ymed #> [1] 27.30 19.20 14.95 # Using R >= 4.1 mtcars |>  eda_3pt(disp, mpg)  # Using magrittr (or any of the tidyverse packages) library(magrittr) mtcars %>% eda_3pt(disp, mpg)"},{"path":"/reference/age_height.html","id":null,"dir":"Reference","previous_headings":"","what":"Age vs. height for private and rural school children — age_height","title":"Age vs. height for private and rural school children — age_height","text":"data reproduced Hoaglin et al.'s book  originally sourced Bernard G. Greenberg (1953) American Journal Public Health (vol 43, pp. 692-699). dataset tabulate children's height weight urban private rural public schools.","code":""},{"path":"/reference/age_height.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Age vs. height for private and rural school children — age_height","text":"","code":"age_height"},{"path":"/reference/age_height.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Age vs. height for private and rural school children — age_height","text":"data frame 18 rows 2 variables: Months Child's age months Height Child's height cm","code":""},{"path":"/reference/age_height.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Age vs. height for private and rural school children — age_height","text":"Understanding robust exploratory data analysis, D.C. Hoaglin,    F. Mosteller J.W. Tukey. (page 135)","code":""},{"path":"/reference/eda_3pt.html","id":null,"dir":"Reference","previous_headings":"","what":"3-point summary plot — eda_3pt","title":"3-point summary plot — eda_3pt","text":"eda_3pt splits data 3 groups (whose summary locations defined respective medians), two half slopes linking groups. function return scatter plot showing half-slopes red solid lines. solid grey slope linking tail-end groups shows desired shape half-slopes. goal two halve slopes line closely possible solid grey slope via re-expression techniques seeking linear relationship variables. function also return half-slopes ratio hsrtio direction re-expression X Y values ladder powers.","code":""},{"path":"/reference/eda_3pt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"3-point summary plot — eda_3pt","text":"","code":"eda_3pt(   dat,   x,   y,   px = 1,   py = 1,   tukey = TRUE,   axes = TRUE,   pch = 21,   equal = TRUE,   p.col = \"grey50\",   p.fill = \"grey80\",   size = 0.8,   alpha = 0.7,   xlab = NULL,   ylab = NULL,   dir = TRUE,   grey = 0.6,   ... )"},{"path":"/reference/eda_3pt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"3-point summary plot — eda_3pt","text":"dat Data frame x Column name assigned x axis y Column name assigned y axis px Power transformation apply x-variable py Power transformation apply y-variable tukey Boolean determining Tukey transformation adopted (FALSE adopts Box-Cox transformation) axes Boolean determining axes drawn. pch Point symbol type equal Boolean determining axes lengths match (.e. squate plot). p.col Color point symbol. p.fill Point fill color passed bg (used pch ranging 21-25). size Point size (0-1) alpha Point transparency (0 = transparent, 1 = opaque). applicable rgb() used define point colors. xlab X label output plot ylab Y label output plot dir Boolean indicating suggested ladder power direction displayed grey Grey level apply plot elements (0 1 1 = black) ... parameters passed graphics::plot function.","code":""},{"path":"/reference/eda_3pt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"3-point summary plot — eda_3pt","text":"Generates plot returns list following named   components: hsrtio: ratio slopes. value close one   suggests transformation needed. xmed: x-coordinate values three summary points. ymed: y-coordinate values three summary points.","code":""},{"path":"/reference/eda_3pt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"3-point summary plot — eda_3pt","text":"Computes three-point summary originally defined Tukey's EDA book (see reference).","code":""},{"path":"/reference/eda_3pt.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"3-point summary plot — eda_3pt","text":"Velleman, P. F., D. C. Hoaglin. 1981. Applications, Basics Computing Exploratory Data Analysis. Boston: Duxbury Press. D. C. Hoaglin, F. Mosteller, J. W. Tukey. 1983. Understanding Robust Exploratory Data Analysis. Wiley. Tukey, John W. 1977. Exploratory Data Analysis. Addison-Wesley.","code":""},{"path":"/reference/eda_3pt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"3-point summary plot — eda_3pt","text":"","code":"hsratio <- eda_3pt(cars, speed, dist)  hsratio <- eda_3pt(cars, speed, dist, py = 1/3, ylab=expression(\"Dist\"^{1/3}))"},{"path":"/reference/eda_add.html","id":null,"dir":"Reference","previous_headings":"","what":"Add graphical EDA elements to exsiting plot — eda_add","title":"Add graphical EDA elements to exsiting plot — eda_add","text":"eda_add  adds graphical EDA elements scatter plot.   Currently adds eda_rline fit points.","code":""},{"path":"/reference/eda_add.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add graphical EDA elements to exsiting plot — eda_add","text":"","code":"eda_add(   x,   pch = 24,   p.col = \"darkred\",   p.fill = \"yellow\",   lty = 1,   l.col = \"darkred\" )"},{"path":"/reference/eda_add.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add graphical EDA elements to exsiting plot — eda_add","text":"x Object class eda_rline pch Point symbol type p.col Point color passed col p.fill Point fill color passed bg (used pch ranging 21-25) lty Line type l.col Line color","code":""},{"path":"/reference/eda_add.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add graphical EDA elements to exsiting plot — eda_add","text":"Returns eda_rline intercept slope. : Intercept b: Slope","code":""},{"path":"/reference/eda_add.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add graphical EDA elements to exsiting plot — eda_add","text":"function adds eda_rline slope 3-pt summary points   existing scatter plot. See accompanying vignette Resistant Line detailed   breakdown resistant line technique.","code":""},{"path":"/reference/eda_add.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add graphical EDA elements to exsiting plot — eda_add","text":"","code":"eda_lm(mtcars, x = wt, y = mpg) #> (Intercept)           x  #>   37.285126   -5.344472  Mr <- eda_rline(mtcars, x=wt, y=mpg) eda_add(Mr, l.col = \"blue\")  #> $a #> [1] 37.763 #>  #> $b #> [1] -5.524372 #>"},{"path":"/reference/eda_bipow.html","id":null,"dir":"Reference","previous_headings":"","what":"Ladder of powers transformation on bivariate data with three-point summary plot — eda_bipow","title":"Ladder of powers transformation on bivariate data with three-point summary plot — eda_bipow","text":"Re-expresses vector ladder powers.  Requires eda_3pt() function.","code":""},{"path":"/reference/eda_bipow.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ladder of powers transformation on bivariate data with three-point summary plot — eda_bipow","text":"","code":"eda_bipow(dat, x, y, p = c(3, 2, 1, 0.5, 0), tukey = TRUE, ...)"},{"path":"/reference/eda_bipow.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ladder of powers transformation on bivariate data with three-point summary plot — eda_bipow","text":"dat Data frame x Column name assigned x axis y Column name assigned y axis p Vector powers tukey set TRUE, adopt Tukey's power transformation. FALSE, adopt Box-Cox transformation. ... parameters passed graphics::plot function.","code":""},{"path":"/reference/eda_bipow.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Ladder of powers transformation on bivariate data with three-point summary plot — eda_bipow","text":"return value","code":""},{"path":"/reference/eda_bipow.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Ladder of powers transformation on bivariate data with three-point summary plot — eda_bipow","text":"Generates matrix scatter plots boxplots various re-expressions x y values. 3-point summary associated half-slopes also plotted (function makes use eda_3pt function). values re-expressed using either Tukey power transformation (default) Box-Cox transformation (see eda_re information transformation techniques). Axes labels omitted reduce plot clutter.","code":""},{"path":"/reference/eda_bipow.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Ladder of powers transformation on bivariate data with three-point summary plot — eda_bipow","text":"Tukey, John W. 1977. Exploratory Data Analysis. Addison-Wesley.","code":""},{"path":"/reference/eda_bipow.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ladder of powers transformation on bivariate data with three-point summary plot — eda_bipow","text":"","code":"eda_bipow(dat = cars, x = speed, y = dist)"},{"path":"/reference/eda_boxls.html","id":null,"dir":"Reference","previous_headings":"","what":"Create boxplots equalized by level and spread — eda_boxls","title":"Create boxplots equalized by level and spread — eda_boxls","text":"eda_boxls creates boxplots conditioned one variable providing option equalize levels /spreads.","code":""},{"path":"/reference/eda_boxls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create boxplots equalized by level and spread — eda_boxls","text":"","code":"eda_boxls(   dat,   x,   fac,   outlier = TRUE,   out.txt,   type = \"l\",   horiz = FALSE,   outliers = TRUE )"},{"path":"/reference/eda_boxls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create boxplots equalized by level and spread — eda_boxls","text":"dat Data frame x Column name assigned values fac Column name assigned factor values conditioned outlier Boolean indicating outliers plotted .txt Column whose values used label outliers type Plot type. \"none\" = equalization ; \"l\" = equalize level; \"ls\" = equalize level spread horiz plot horizontally (TRUE) vertically (FALSE) outliers plot outliers (TRUE) (FALSE)","code":""},{"path":"/reference/eda_boxls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create boxplots equalized by level and spread — eda_boxls","text":"return value","code":""},{"path":"/reference/eda_boxls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create boxplots equalized by level and spread — eda_boxls","text":"","code":"# A basic boxplot (no equalization) eda_boxls(mtcars,mpg, cyl, type=\"none\", out.txt=mpg )   # Boxplots equalized by level eda_boxls(mtcars,mpg, cyl, type=\"l\", out.txt=mpg )   # Boxplots equalized by level and spread eda_boxls(mtcars,mpg, cyl, type=\"ls\", out.txt=mpg )   # Hide outlier eda_boxls(mtcars,mpg, cyl, type=\"ls\", out.txt=mpg , outlier=FALSE)"},{"path":"/reference/eda_lm.html","id":null,"dir":"Reference","previous_headings":"","what":"Least Squares regression plot (with optional LOESS fit) — eda_lm","title":"Least Squares regression plot (with optional LOESS fit) — eda_lm","text":"eda_lm generates scatter plot fitted regression   line. loess line can  also added plot model comparison.   axes scaled respective standard  deviations match axes   unit length.","code":""},{"path":"/reference/eda_lm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Least Squares regression plot (with optional LOESS fit) — eda_lm","text":"","code":"eda_lm(   dat,   x,   y,   xlab = NULL,   ylab = NULL,   px = 1,   py = 1,   tukey = FALSE,   reg = TRUE,   w = NULL,   sd = TRUE,   grey = 0.6,   pch = 21,   p.col = \"grey50\",   p.fill = \"grey80\",   size = 0.8,   alpha = 0.8,   q = FALSE,   q.val = c(0.16, 0.84),   q.type = 5,   loe = FALSE,   lm.col = rgb(1, 0.5, 0.5, 0.8),   loe.col = rgb(0.3, 0.3, 1, 1),   stats = FALSE,   loess.d = list(family = \"symmetric\", span = 0.7, degree = 1),   ... )"},{"path":"/reference/eda_lm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Least Squares regression plot (with optional LOESS fit) — eda_lm","text":"dat Data frame x Column assigned x axis y Column assigned y axis xlab X label output plot ylab Y label output plot px Power transformation apply x-variable py Power transformation apply y-variable tukey Boolean determining Tukey transformation adopted (FALSE adopts Box-Cox transformation) reg Boolean indicating whether least squares regression line plotted w Weight pass regression model sd Boolean determining standard deviation lines plotted grey Grey level apply plot elements (0 1 1 = black) pch Point symbol type p.col Color point symbol. p.fill Point fill color passed bg (used pch ranging 21-25). size Point size (0-1) alpha Point transparency (0 = transparent, 1 = opaque). applicable rgb() used define point colors. q Boolean determining grey quantile boxes plotted q.val F-values use define quantile box parameters. Defaults mid 68 used generate box. q.type Quantile type. Defaults 5 (Cleveland's f-quantile definition) loe Boolean indicating loess curve fitted lm.col Regression line color loe.col LOESS curve color stats Boolean indicating regression summary statistics displayed loess.d list parameters passed loess.smooth function. robust loess used default. ... used","code":""},{"path":"/reference/eda_lm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Least Squares regression plot (with optional LOESS fit) — eda_lm","text":"Returns list  `lm` output. : Intercept b: Slope residuals: Regression model residuals","code":""},{"path":[]},{"path":"/reference/eda_lm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Least Squares regression plot (with optional LOESS fit) — eda_lm","text":"","code":"# Add a regular (OLS) regression model and loess smooth to the data eda_lm(mtcars, wt, mpg, loe = TRUE)  #> (Intercept)           x  #>   37.285126   -5.344472   # Add the inner 68% quantile to compare the true 68% of data to the SD eda_lm(mtcars, wt, mpg, loe = TRUE, q = TRUE)  #> (Intercept)           x  #>   37.285126   -5.344472   # Show the IQR box eda_lm(mtcars, wt, mpg, loe = TRUE, q = TRUE, sd = FALSE, q.val = c(0.25,0.75))  #> (Intercept)           x  #>   37.285126   -5.344472   # Fit an OLS to the Income for Female vs Male df2 <- read.csv(\"https://mgimond.github.io/ES218/Data/Income_education.csv\") eda_lm(df2, x=B20004013, y = B20004007, xlab = \"Female\", ylab = \"Male\",             loe = TRUE)  #>  (Intercept)            x  #> 10503.090485     1.086416   # Add the inner 68% quantile to compare the true 68% of data to the SD eda_lm(df2, x = B20004013, y = B20004007, xlab = \"Female\", ylab = \"Male\",             q = TRUE)  #>  (Intercept)            x  #> 10503.090485     1.086416   # Apply a transformation to x and y axes: x -> 1/3 and y -> log eda_lm(df2, x = B20004013, y = B20004007, xlab = \"Female\", ylab = \"Male\",             px = 1/3, py = 0, q = TRUE, loe = TRUE)  #> (Intercept)           x  #>  8.58646713  0.02287702"},{"path":"/reference/eda_lsum.html","id":null,"dir":"Reference","previous_headings":"","what":"Tukey's letter value summaries — eda_lsum","title":"Tukey's letter value summaries — eda_lsum","text":"eda_lsum letter value summary introduced John Tukey extends boxplot's 5 number summary exploring symmetry batch depth levels half (median) fourth (quartiles).","code":""},{"path":"/reference/eda_lsum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tukey's letter value summaries — eda_lsum","text":"","code":"eda_lsum(x, l = 5, all = TRUE)"},{"path":"/reference/eda_lsum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tukey's letter value summaries — eda_lsum","text":"x Vector l Number levels (max = 9) Generate upper, lower mid summaries TRUE just generate mid summaries FALSE","code":""},{"path":"/reference/eda_lsum.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tukey's letter value summaries — eda_lsum","text":"Returns dataframe letter value summaries.","code":""},{"path":"/reference/eda_lsum.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Tukey's letter value summaries — eda_lsum","text":"Outputs data frame letter value summaries.","code":""},{"path":"/reference/eda_lsum.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Tukey's letter value summaries — eda_lsum","text":"Exploratory Data Analysis, John Tukey, 1973.","code":""},{"path":[]},{"path":"/reference/eda_lsum.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tukey's letter value summaries — eda_lsum","text":"","code":"x <- c(22, 8, 11, 3, 26, 1, 14, 18, 20, 25, 24) eda_lsum(x) #>   letter depth lower   mid upper spread #> 1      M   6.0  18.0 18.00  18.0    0.0 #> 2      H   3.5   9.5 16.25  23.0   13.5 #> 3      E   2.0   3.0 14.00  25.0   22.0 #> 4      D   1.5   2.0 13.75  25.5   23.5 #> 5      C   1.0   1.0 13.50  26.0   25.0"},{"path":"/reference/eda_pol.html","id":null,"dir":"Reference","previous_headings":"","what":"Polish two-way tables — eda_pol","title":"Polish two-way tables — eda_pol","text":"eda_pol Polishes two-way tables using median, means,   customizable functions.","code":""},{"path":"/reference/eda_pol.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Polish two-way tables — eda_pol","text":"","code":"eda_pol(   x,   row = NULL,   col = NULL,   val = NULL,   stat = median,   plot = TRUE,   eps = 0.01,   maxiter = 5,   sort = FALSE,   p = 1,   tukey = FALSE,   offset = 1e-05,   col.quant = FALSE,   colpal = \"RdYlBu\",   adj.mar = FALSE,   res.size = 1,   row.size = 1,   col.size = 1,   res.txt = TRUE,   label.txt = TRUE )"},{"path":"/reference/eda_pol.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Polish two-way tables — eda_pol","text":"x three column data frame row Name column assigned row effect col Name column assigned column effect val Name column assigned response variable stat Polishing statistic (default median) plot Boolean determining output plot generated eps Convergence tolerance parameter maxiter Maximum number iterations sort Boolean determining effects row/columns sorted p Re-expression power parameter tukey Boolean determining Tukey's power transformation used. FALSE, Box-Cox transformation adopted. offset Offset add values leat one value 0 power negative col.quant Boolean determining quantile classification scheme used colpal Color palette adopt adj.mar Boolean determining margin width needs accomodate labels res.size Size residual values plot [0-1] row.size Size row effect values plot [0-1] col.size Size column effect values plot [0-1] res.txt Boolean determining values added plot label.txt Boolean determining margin column labels plotted","code":""},{"path":"/reference/eda_pol.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Polish two-way tables — eda_pol","text":"list class eda_polish following named   components: long median polish residuals three columns: Column levels,   row levels residual values. wide median polish residuals table wide form. row  Row effects table col  Column effects table global  Overall value (common value) iter  Number iterations polish stabilizes. cv  Table residuals, row effects, column effects CV values long form. power  Transformation power applied values prior polishing. IQ_row  Ratio interquartile row effect values 80th quantile residuals. IQ_col  Ratio interquartile column effect values 80th quantile residuals.","code":""},{"path":"/reference/eda_pol.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Polish two-way tables — eda_pol","text":"function performs polish two way table. default,   applies median polish, statistical summaries mean   can passed function via stat =  parameter.   function returns list row/column effects along global   residual values. also generate colored table plot =   TRUE.","code":""},{"path":"/reference/eda_pol.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Polish two-way tables — eda_pol","text":"","code":"df <- data.frame(region =  rep( c(\"NE\", \"NC\", \"S\", \"W\"), each = 5), edu = rep( c(\"ed8\", \"ed9to11\", \"ed12\", \"ed13to15\", \"ed16\"), 4), perc = c(25.3, 25.3, 18.2, 18.3, 16.3, 32.1, 29, 18.8,         24.3, 19, 38.8, 31, 19.3, 15.7, 16.8, 25.4, 21.1, 20.3, 24, 17.5))  eda_pol(df, row = region, col = edu, val = perc, plot = FALSE) #> $long #>         edu region     perc #> 1      ed12     NC -3.15625 #> 2      ed12     NE  0.00625 #> 3      ed12      W  0.29375 #> 4      ed12      S -0.00625 #> 5  ed13to15     NE -1.11875 #> 6  ed13to15      S -4.83125 #> 7  ed13to15     NC  1.11875 #> 8  ed13to15      W  2.76875 #> 9      ed16      S  0.00000 #> 10     ed16     NC -0.45000 #> 11     ed16      W  0.00000 #> 12     ed16     NE  0.61250 #> 13      ed8     NC  1.51875 #> 14      ed8     NE -1.51875 #> 15      ed8      S 10.86875 #> 16      ed8      W -3.23125 #> 17  ed9to11     NE  0.03125 #> 18  ed9to11     NC -0.03125 #> 19  ed9to11      S  4.61875 #> 20  ed9to11      W -5.98125 #>  #> $wide #>         eff     ed12 ed13to15    ed16      ed8  ed9to11 #> eff 20.8500 -1.19375  0.03125 -3.7000  7.43125  5.88125 #> NC   2.3000 -3.15625  1.11875 -0.4500  1.51875 -0.03125 #> NE  -1.4625  0.00625 -1.11875  0.6125 -1.51875  0.03125 #> S   -0.3500 -0.00625 -4.83125  0.0000 10.86875  4.61875 #> W    0.3500  0.29375  2.76875  0.0000 -3.23125 -5.98125 #>  #> $row #>   region  effect #> 1     NC  2.3000 #> 2     NE -1.4625 #> 3      S -0.3500 #> 4      W  0.3500 #>  #> $col #>        edu   effect #> 1     ed12 -1.19375 #> 2 ed13to15  0.03125 #> 3     ed16 -3.70000 #> 4      ed8  7.43125 #> 5  ed9to11  5.88125 #>  #> $global #> [1] 20.85 #>  #> $iter #> [1] 5 #>  #> $cv #>        perc region.eff  edu.eff            cv #> 1  -3.15625     2.3000 -1.19375 -0.1316846523 #> 2  -0.00625    -0.3500 -1.19375  0.0200389688 #> 3   0.00625    -1.4625 -1.19375  0.0837342626 #> 4   0.29375     0.3500 -1.19375 -0.0200389688 #> 5  -4.83125    -0.3500  0.03125 -0.0005245803 #> 6   1.11875     2.3000  0.03125  0.0034472422 #> 7   2.76875     0.3500  0.03125  0.0005245803 #> 8  -1.11875    -1.4625  0.03125 -0.0021919964 #> 9  -0.45000     2.3000 -3.70000 -0.4081534772 #> 10  0.61250    -1.4625 -3.70000  0.2595323741 #> 11  0.00000     0.3500 -3.70000 -0.0621103118 #> 12  0.00000    -0.3500 -3.70000  0.0621103118 #> 13 -1.51875    -1.4625  7.43125 -0.5212567446 #> 14 10.86875    -0.3500  7.43125 -0.1247452038 #> 15  1.51875     2.3000  7.43125  0.8197541966 #> 16 -3.23125     0.3500  7.43125  0.1247452038 #> 17 -0.03125     2.3000  5.88125  0.6487709832 #> 18  0.03125    -1.4625  5.88125 -0.4125337230 #> 19  4.61875    -0.3500  5.88125 -0.0987260192 #> 20 -5.98125     0.3500  5.88125  0.0987260192 #>  #> $power #> [1] 1 #>  #> $IQ_row #> [1] 0.4177057 #>  #> $IQ_col #> [1] 2.016388 #>  #> attr(,\"class\") #> [1] \"eda_polish\""},{"path":"/reference/eda_qq.html","id":null,"dir":"Reference","previous_headings":"","what":"Generates empirical QQ plot and Tukey mean-difference plot — eda_qq","title":"Generates empirical QQ plot and Tukey mean-difference plot — eda_qq","text":"eda_qq generates empirical QQ plot Tukey   mean-difference plot","code":""},{"path":"/reference/eda_qq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generates empirical QQ plot and Tukey mean-difference plot — eda_qq","text":"","code":"eda_qq(   x,   y,   px = 1,   py = 1,   q.type = 5,   tukey = FALSE,   md = FALSE,   plot = TRUE,   grey = 0.6,   pch = 21,   p.col = \"grey50\",   p.fill = \"grey80\",   size = 0.8,   alpha = 0.8,   q = TRUE,   q.val = c(0.25, 0.75),   xlab = NULL,   ylab = NULL,   ... )"},{"path":"/reference/eda_qq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generates empirical QQ plot and Tukey mean-difference plot — eda_qq","text":"x Column assigned x axis. y Column assigned y axis. px Power transformation apply x-variable. py Power transformation apply y-variable. q.type Quantile type. Defaults 5 (Cleveland's f-quantile definition) tukey Boolean determining Tukey transformation adopted (FALSE adopts Box-Cox transformation). md Boolean determining Tukey mean-difference plot generated. plot Boolean determining plot generated. grey Grey level apply plot elements (0 1 1 = black). pch Point symbol type. p.col Color point symbol. p.fill Point fill color passed bg (used pch ranging 21-25). size Point size (0-1) alpha Point transparency (0 = transparent, 1 = opaque). applicable rgb() used define point colors. q Boolean determining grey quantile boxes plotted q.val F-values use define quantile box parameters. Defaults mid 68 used generate box. xlab X label output plot ylab Y label output plot ... used","code":""},{"path":"/reference/eda_qq.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generates empirical QQ plot and Tukey mean-difference plot — eda_qq","text":"","code":"# Compare \"Tenor 1\" and \"Bass 2\" singer height batches  singer <- lattice::singer  bass2 <- subset(singer, voice.part == \"Bass 2\", select = height, drop = TRUE )  tenor1 <- subset(singer, voice.part == \"Tenor 1\", select = height, drop = TRUE )  eda_qq(bass2, tenor1, xlab=\"bass 2\", ylab=\"tenor 1\")    # There seems to be an additive offset of about 2 inches  eda_qq(tenor1, bass2 - 2,  xlab=\"bass 2\", ylab=\"tenor 1\")    # We can fine-tune by generating the Tukey mean-difference plot  eda_qq(tenor1, bass2 - 2, xlab=\"bass 2\", ylab=\"tenor 1\", md = TRUE)    # An offset of another 0.5 inches seems warranted  eda_qq(tenor1, bass2 - 2.5, xlab=\"bass 2\", ylab=\"tenor 1\", md = TRUE)    # We can also apply the offset to the x variable  eda_qq(tenor1 + 2.5, bass2, xlab=\"bass 2\", ylab=\"tenor 1\", md = TRUE)    # Suppress plot and output values to object  out <- eda_qq(tenor1, bass2, plot = FALSE)"},{"path":"/reference/eda_re.html","id":null,"dir":"Reference","previous_headings":"","what":"Re-expression function — eda_re","title":"Re-expression function — eda_re","text":"eda_re re-expresses vector following Tukey box-cox transformation.","code":""},{"path":"/reference/eda_re.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Re-expression function — eda_re","text":"","code":"eda_re(x, p = 0, tukey = TRUE)"},{"path":"/reference/eda_re.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Re-expression function — eda_re","text":"x Vector p Power transformation tukey set TRUE, adopt Tukey's power transformation, FALSE, adopt Box-Cox transformation","code":""},{"path":"/reference/eda_re.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Re-expression function — eda_re","text":"Returns vector length input x","code":""},{"path":"/reference/eda_re.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Re-expression function — eda_re","text":"function used re-express data using one two transformation techniques: Box-Cox transformation (tukey = FALSE)Tukey's power transformation (tukey = TRUE).","code":""},{"path":"/reference/eda_re.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Re-expression function — eda_re","text":"","code":"x <- c(15, 28, 17, 73,  8, 83,  2) eda_re(x, p=-1/3) #> [1] 0.4054801 0.3293169 0.3889111 0.2392723 0.5000000 0.2292489 0.7937005"},{"path":"/reference/eda_rline.html","id":null,"dir":"Reference","previous_headings":"","what":"Tukey's resistant line — eda_rline","title":"Tukey's resistant line — eda_rline","text":"eda_rline R implementation Hoaglin, Mosteller   Tukey's resistant line technique outlined chapter 5   \"Understanding Robust Exploratory Data Analysis\" (Wiley, 1983).","code":""},{"path":"/reference/eda_rline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tukey's resistant line — eda_rline","text":"","code":"eda_rline(dat, x, y, px = 1, py = 1, tukey = TRUE)"},{"path":"/reference/eda_rline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tukey's resistant line — eda_rline","text":"dat Data frame x Column assigned x axis y Column assigned y axis px Power transformation apply x-variable py Power transformation apply y-variable tukey Boolean determining Tukey transformation adopted (FALSE adopts Box-Cox transformation)","code":""},{"path":"/reference/eda_rline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tukey's resistant line — eda_rline","text":"Returns list class eda_rlinewith following named   components: : Intercept b: Slope res: Residuals sorted x-values x: Sorted x values y: y values following sorted x-values xmed: Median x values third ymed: Median y values third index: Index sorted x values defining upper boundaries                      thirds xlab: X label name ylab: Y label name iter: Number iterations","code":""},{"path":"/reference/eda_rline.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Tukey's resistant line — eda_rline","text":"R implementation RLIN.F FORTRAN code   Velleman et. al's book. function fits robust line using   three-point summary strategy whereby data split three equal   length groups along x-axis line fitted medians defining   group via iterative process. function mirror   built-stat::line function fitting strategy outputs   additional parameters. See accompanying vignette Resistant Line detailed   breakdown resistant line technique.","code":""},{"path":"/reference/eda_rline.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Tukey's resistant line — eda_rline","text":"Velleman, P. F., D. C. Hoaglin. 1981. Applications, Basics Computing Exploratory Data Analysis. Boston: Duxbury Press. D. C. Hoaglin, F. Mosteller, J. W. Tukey. 1983. Understanding Robust Exploratory Data Analysis. Wiley.","code":""},{"path":"/reference/eda_rline.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tukey's resistant line — eda_rline","text":"","code":"# This first example uses breast cancer data from \"ABC's of EDA\" page 127. # The output model's  parameters should closely match:  Y = -46.19 + 2.89X # The plots shows the original data with a fitted resistant line (red) # and a regular lm fitted line (dashed line), and the modeled residuals. # The 3-point summary dots are shown in red.  M <- eda_rline(neoplasms, Temp, Mortality) M #> $b #> [1] 2.890173 #>  #> $a #> [1] -45.90578 #>  #> $res #>  [1]  21.2982659   0.1398844  -2.1791908   8.8294798 -11.2485549  -7.6167630 #>  [7]  -0.1398844   4.7589595  -9.0092486  -2.1994220   2.7554913  -7.2676301 #> [13]  -0.3907514   6.1861272   1.7971098   0.1398844 #>  #> $x #>  [1] 31.8 34.0 40.2 42.1 42.3 43.5 44.2 45.1 46.3 47.3 47.8 48.5 49.2 49.9 50.0 #> [16] 51.3 #>  #> $y #>  [1]  67.3  52.5  68.1  84.6  65.1  72.2  81.7  89.2  78.9  88.6  95.0  87.0 #> [13]  95.9 104.5 100.4 102.5 #>  #> $xmed #> [1] 40.2 45.7 49.9 #>  #> $ymed #> [1]  67.30  85.15 100.40 #>  #> $index #> [1]  5 11 16 #>  #> $xlab #> [1] \"Temp\" #>  #> $ylab #> [1] \"Mortality\" #>  #> $px #> [1] 1 #>  #> $py #> [1] 1 #>  #> $iter #> [1] 4 #>  #> attr(,\"class\") #> [1] \"eda_rline\"  # Plot the output plot(M) abline(lm(Mortality ~ Temp, neoplasms), lty = 3)   # Plot the residuals plot(M, type = \"residuals\")   # This next example models gas consumption as a function of engine displacement. # It applies a transformation to both variables via the px and py arguments. eda_3pt(mtcars, disp, mpg,  px = -1/3, py = -1,        ylab = \"gal/mi\", xlab = expression(\"Displacement\"^{-1/3}))  #> $slope1 #> [1] -0.3633401 #>  #> $slope2 #> [1] -0.4098173 #>  #> $hsrtio #> [1] 1.127916 #>  #> $xmed #> [1] 0.1405721 0.1813741 0.2190819 #>  #> $ymed #> [1] 0.06690834 0.05208333 0.03663004 #>   # This next example uses Andrew Siegel's pathological 9-point dataset to test # for model stability when convergence cannot be reached. M <- eda_rline(nine_point, X, Y) plot(M)"},{"path":"/reference/eda_sl.html","id":null,"dir":"Reference","previous_headings":"","what":"Tukey's spread-level function — eda_sl","title":"Tukey's spread-level function — eda_sl","text":"eda_sl function generates spread-level table univariate dataset.","code":""},{"path":"/reference/eda_sl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tukey's spread-level function — eda_sl","text":"","code":"eda_sl(dat, x, y, sprd = \"frth\")"},{"path":"/reference/eda_sl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tukey's spread-level function — eda_sl","text":"dat Dataframe x Categorical variable column y Continuous variable column sprd Choice spreads. Either interquartile, sprd = \"IQR\" fourth-spread, sprd = \"frth\" (default).","code":""},{"path":"/reference/eda_sl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tukey's spread-level function — eda_sl","text":"Returns dataframe level spreads.","code":""},{"path":"/reference/eda_sl.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Tukey's spread-level function — eda_sl","text":"Note function confused Bill Cleveland's   spread-location function. x categorical, output produce many NA's. page 59, Hoaglan et. al define fourth-spread range   defined upper fourth lower fourth. eda_lsum function used   compute upper/lower fourths.","code":""},{"path":"/reference/eda_sl.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Tukey's spread-level function — eda_sl","text":"Understanding Robust Exploratory Data Analysis, Hoaglin, David C., Frederick Mosteller, John W. Tukey, 1983.","code":""},{"path":"/reference/eda_sl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tukey's spread-level function — eda_sl","text":"","code":"sl <- eda_sl(iris, Species, Sepal.Length) plot(spread ~ level, sl, pch=16)"},{"path":"/reference/eda_trim.html","id":null,"dir":"Reference","previous_headings":"","what":"Trims vector and dataframe objects — eda_trim","title":"Trims vector and dataframe objects — eda_trim","text":"Removes records either tail-ends sorted dataset. Trimming can performed number records (specify num = option) quantiles (specify prop= option). eda_trim Trims vector eda_trim_df Trims data frame eda_ltrim Left-trims vector eda_rtrim Right-trims vector eda_ltrim_df Left-trims dataframe eda_rtrim_df Right-trims dataframe","code":""},{"path":"/reference/eda_trim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trims vector and dataframe objects — eda_trim","text":"","code":"eda_trim(x, prop = 0.05, num = 0)  eda_trim_df(dat, x, prop = 0.05, num = 0)  eda_ltrim(x, prop = 0.05, num = 0)  eda_ltrim_df(dat, x, prop = 0.05, num = 0)  eda_rtrim(x, prop = 0.05, num = 0)  eda_rtrim_df(dat, x, prop = 0.05, num = 0)"},{"path":"/reference/eda_trim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Trims vector and dataframe objects — eda_trim","text":"x Vector values (trimming vector) column whose values used trim dataframe (applies *_df functions ) prop Fraction values trim num Number values trim dat Dataframe (applies *_df functions )","code":""},{"path":"/reference/eda_trim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Trims vector and dataframe objects — eda_trim","text":"Returns data type input (.e. vector dataframe)","code":""},{"path":"/reference/eda_trim.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Trims vector and dataframe objects — eda_trim","text":"input dataset need sorted (sorting performed  functions). num set zero, function assume  trimming done fraction (defined prop parameter). eda_trim eda_trim_df functions called,  num prop values apply tail. example,  num = 5 5 smallest 5 largest values removed  data. NA values must stripped input vector  column elements running trim functions. Elements returned sorted trimmed elements.","code":""},{"path":"/reference/eda_trim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Trims vector and dataframe objects — eda_trim","text":"","code":"# Trim a vector by 10% (i.e. 10% of the smallest and 10% of the largest # values) eda_trim( mtcars[,1], prop=0.1) #>  [1] 14.7 15.0 15.2 15.2 15.5 15.8 16.4 17.3 17.8 18.1 18.7 19.2 19.2 19.7 21.0 #> [16] 21.0 21.4 21.4 21.5 22.8 22.8 24.4 26.0 27.3  # Trim a data frame by 10% using the mpg column(i.e. 10% of the smallest # and 10% of the largest mpg values) eda_trim_df( mtcars, mpg, prop=0.1) #>                    mpg cyl  disp  hp drat    wt  qsec vs am gear carb #> Chrysler Imperial 14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4 #> Maserati Bora     15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8 #> Merc 450SLC       15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3 #> AMC Javelin       15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2 #> Dodge Challenger  15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2 #> Ford Pantera L    15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4 #> Merc 450SE        16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3 #> Merc 450SL        17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3 #> Merc 280C         17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4 #> Valiant           18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1 #> Hornet Sportabout 18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2 #> Merc 280          19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4 #> Pontiac Firebird  19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2 #> Ferrari Dino      19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6 #> Mazda RX4         21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4 #> Mazda RX4 Wag     21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4 #> Hornet 4 Drive    21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1 #> Volvo 142E        21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2 #> Toyota Corona     21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1 #> Datsun 710        22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1 #> Merc 230          22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2 #> Merc 240D         24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2 #> Porsche 914-2     26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2 #> Fiat X1-9         27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1"},{"path":"/reference/eda_unipow.html","id":null,"dir":"Reference","previous_headings":"","what":"Ladder of powers transformation on a single vector — eda_unipow","title":"Ladder of powers transformation on a single vector — eda_unipow","text":"eda_unipow re-expresses vector ladder powers   plots results using histogram density function. Either   Tukey Box-Cox transformation used computing re-expressed   values.","code":""},{"path":"/reference/eda_unipow.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ladder of powers transformation on a single vector — eda_unipow","text":"","code":"eda_unipow(   x,   p = c(2, 1, 1/2, 0.33, 0, -0.33, -1/2, -1, -2),   tukey = TRUE,   bins = 5,   cex.main = 1.3,   col = \"#DDDDDD\",   border = \"#AAAAAA\",   title = \"Re-expressed data via ladder of powers\",   ... )"},{"path":"/reference/eda_unipow.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ladder of powers transformation on a single vector — eda_unipow","text":"x Vector p Vector powers tukey TRUE (default), apply Tukey's power transformation, FALSE adopt Box-Cox transformation bins Number histogram bins cex.main Histogram title size (assigned histogram plot) col Histogram fill color border Histogram border color title Overall plot title (set NULL title) ... parameters passed graphics::hist function.","code":""},{"path":"/reference/eda_unipow.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Ladder of powers transformation on a single vector — eda_unipow","text":"return value","code":""},{"path":"/reference/eda_unipow.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Ladder of powers transformation on a single vector — eda_unipow","text":"output lattice descriptive plots showing transformed data across different powers.","code":""},{"path":"/reference/eda_unipow.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Ladder of powers transformation on a single vector — eda_unipow","text":"Tukey, John W. 1977. Exploratory Data Analysis. Addison-Wesley.","code":""},{"path":"/reference/eda_unipow.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ladder of powers transformation on a single vector — eda_unipow","text":"","code":"data(mtcars) eda_unipow(mtcars$mpg, bins=6)"},{"path":"/reference/neoplasms.html","id":null,"dir":"Reference","previous_headings":"","what":"Breast cancer mortality vs. temperature — neoplasms","title":"Breast cancer mortality vs. temperature — neoplasms","text":"data represent relationship mean annual temperature breast cancer mortality rate.","code":""},{"path":"/reference/neoplasms.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Breast cancer mortality vs. temperature — neoplasms","text":"","code":"neoplasms"},{"path":"/reference/neoplasms.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Breast cancer mortality vs. temperature — neoplasms","text":"data frame 16 rows 2 variables: Temp Temperature degrees Fahrenheit. Mortality Mortality rate presented index.","code":""},{"path":"/reference/neoplasms.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Breast cancer mortality vs. temperature — neoplasms","text":"Applications, Basics Computing Exploratory Data Analysis,       P.F. Velleman D.C. Hoaglin, 1981. (page 127)","code":""},{"path":"/reference/nine_point.html","id":null,"dir":"Reference","previous_headings":"","what":"Andrew Siegel's pathological 9-point dataset — nine_point","title":"Andrew Siegel's pathological 9-point dataset — nine_point","text":"synthetic dataset created test robustness fitted lines. Originally published Andrew Siegel later adapted Hoaglin et al.'s book.","code":""},{"path":"/reference/nine_point.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Andrew Siegel's pathological 9-point dataset — nine_point","text":"","code":"nine_point"},{"path":"/reference/nine_point.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Andrew Siegel's pathological 9-point dataset — nine_point","text":"data frame 9 rows 2 variables: X X values Y Y values","code":""},{"path":"/reference/nine_point.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Andrew Siegel's pathological 9-point dataset — nine_point","text":"Robust regression using repeated medians, Andrew F. Siegel, Biometrika,    vol 69, n 1, 1982. Understanding robust exploratory data analysis, D.C. Hoaglin,    F. Mosteller J.W. Tukey. 1983 (page 139)","code":""},{"path":"/reference/plot.eda_polish.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot eda_polish tables or diagnostic plots — plot.eda_polish","title":"Plot eda_polish tables or diagnostic plots — plot.eda_polish","text":"plot.eda_pol plot method lists eda_polish class.","code":""},{"path":"/reference/plot.eda_polish.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot eda_polish tables or diagnostic plots — plot.eda_polish","text":"","code":"# S3 method for eda_polish plot(   x,   type = \"residuals\",   add.cv = FALSE,   k = NULL,   col.quant = FALSE,   colpal = \"RdYlBu\",   colrev = TRUE,   col.eff = TRUE,   col.com = TRUE,   adj.mar = FALSE,   res.size = 1,   row.size = 1,   col.size = 1,   res.txt = TRUE,   label.txt = TRUE,   ... )"},{"path":"/reference/plot.eda_polish.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot eda_polish tables or diagnostic plots — plot.eda_polish","text":"x list class eda_polish type Plot type. One three: \"residuals\", \"cv\" \"diagnostic\". add.cv Whether add kCV model plotting \"residuals\" k Custom k use kCV added model. value NULL makes us slope. col.quant Boolean indicating quantile classification scheme used colpal Color palette adopt (one listed hcl.pals()) colrev color palette reversed? (default TRUE) col.eff Boolean indicating effects common value contribute color gradient col.com Boolean indicating common value contribute color gradient adj.mar Boolean indicating margin width needs accommodate labels res.size Size residual values plot [0-1] row.size Size row effect values plot [0-1] col.size Size column effect values plot [0-1] res.txt Boolean indicating values added plot label.txt Boolean indicating margin column labels plotted ... Arguments passed subsequent methods","code":""},{"path":"/reference/plot.eda_polish.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot eda_polish tables or diagnostic plots — plot.eda_polish","text":"Returns single element vector \"type\" \"diagnostic\" value   otherwise.","code":""},{"path":"/reference/plot.eda_polish.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot eda_polish tables or diagnostic plots — plot.eda_polish","text":"function plots polish table residuals CV values. also generate diagnostic plot type set diagnostic","code":""},{"path":"/reference/plot.eda_polish.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot eda_polish tables or diagnostic plots — plot.eda_polish","text":"","code":"# Create dataset df <- data.frame(region =  rep( c(\"NE\", \"NC\", \"S\", \"W\"), each = 5), edu = rep( c(\"ed8\", \"ed9to11\", \"ed12\", \"ed13to15\", \"ed16\"), 4), perc = c(25.3, 25.3, 18.2, 18.3, 16.3, 32.1, 29, 18.8,         24.3, 19, 38.8, 31, 19.3, 15.7, 16.8, 25.4, 21.1, 20.3, 24, 17.5))  # Generate median polish output out <- eda_pol(df, row = region, col = edu, val = perc, plot = FALSE)  # Plot table plot(out, type = \"residuals\")    # Plot table using CV values plot(out, type = \"cv\")   # Generate diagnostic plot plot(out, type = \"diagnostic\")  #> $slope #>     cv  #> 1.3688  #>"},{"path":"/reference/plot.eda_rline.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot eda_rline model — plot.eda_rline","title":"Plot eda_rline model — plot.eda_rline","text":"plot.eda_rline plot method lists eda_rline  class.","code":""},{"path":"/reference/plot.eda_rline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot eda_rline model — plot.eda_rline","text":"","code":"# S3 method for eda_rline plot(   x,   type = \"model\",   xlab = NULL,   ylab = NULL,   grey = 0.7,   pch = 21,   equal = TRUE,   p.col = \"grey50\",   p.fill = \"grey80\",   size = 0.8,   alpha = 0.7,   model = TRUE,   pt3 = TRUE,   ... )"},{"path":"/reference/plot.eda_rline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot eda_rline model — plot.eda_rline","text":"x Object class eda_rline type Plot type. One two: \"model\", \"residuals\". xlab Custom x-axis label. Defaults column name ylab Custom y-axis label. Defaults column name. grey Grey level apply plot elements (0 1 1 = black) pch Point symbol type equal Boolean determining axes lengths match (.e. squate plot). p.col Color point symbol. p.fill Point fill color passed bg (used pch ranging 21-25). size Point size (0-1) alpha Point transparency (0 = transparent, 1 = opaque). applicable rgb() used define point colors. model Boolean indicating resulting model added plot. applies type = \"model\" pt3 Boolean indicating 3-pt summaries added plot. applies type = \"model\" ... Arguments passed subsequent methods","code":""},{"path":"/reference/plot.eda_rline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot eda_rline model — plot.eda_rline","text":"return value.","code":""},{"path":"/reference/plot.eda_rline.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot eda_rline model — plot.eda_rline","text":"function generates scatter plot fitted model  eda_rline object.","code":""},{"path":"/reference/plot.eda_rline.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot eda_rline model — plot.eda_rline","text":"","code":"r.lm    <- eda_rline(age_height, Months, Height)  plot(r.lm)  plot(r.lm, type = \"residuals\")"},{"path":"/reference/tukeyedar.html","id":null,"dir":"Reference","previous_headings":"","what":"Tukey inspired exploratory data analysis functions — tukeyedar","title":"Tukey inspired exploratory data analysis functions — tukeyedar","text":"packages hosts small set Tukey inspired functions use exploring datasets robust manner.","code":""},{"path":"/news/index.html","id":"tukeyedar-011","dir":"Changelog","previous_headings":"","what":"tukeyedar 0.1.1","title":"tukeyedar 0.1.1","text":"Introduces median polish function eda_pol. Introduces QQ Tukey mean-difference plot eda.qq. Adds re-expression parameters eda_lm via parameters px py. Adds sd labels SD dashed lines eda_lm. eda_lm now output lm intercept slope. Adds plot method eda_rline object. eda_re p = 1, box-cox option ignored. Homogenize plot appearances","code":""},{"path":"/news/index.html","id":"tukeyedar-010","dir":"Changelog","previous_headings":"","what":"tukeyedar 0.1.0","title":"tukeyedar 0.1.0","text":"Initial release tukeyedar","code":""}]
